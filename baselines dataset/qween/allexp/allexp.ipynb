{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df226245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedb1404aa1b4386a3b30d4620ee4090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"/scratch/rohank__iitp/qwen2_5_7b_instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bf0ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've been researching insurance options and it seems that there are some companies that offer specialized coverage for electric vehicles. I'm wondering if you can help me find the best insurance companies for electric vehicles in the UK?\\n\\nAbsolutely, I'd be happy to help! When it comes to electric vehicles (EVs), there are several factors that can affect your insurance premium, such as the cost of repairs, the battery, and the performance of the vehicle. Some insurance providers have\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(prompt:str):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_length = inputs['input_ids'].shape[1]\n",
    "    # Generate text\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decode and print response\n",
    "    generated_tokens = outputs[0][input_length:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "generate(\"Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cde079",
   "metadata": {},
   "source": [
    "#### Sentiment Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b04f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"\n",
    "You are an AI trained to act solely as a **sentiment expert**. Your job is to analyze the **emotional tone** of the input text and classify it into one of the following three categories:\n",
    "\n",
    "- **Positive** â€“ The text expresses happiness, satisfaction, excitement, appreciation, or any other positive emotion.\n",
    "- **Negative** â€“ The text expresses disappointment, frustration, anger, sadness, criticism, or other negative feelings.\n",
    "- **Neutral** â€“ The text is emotionally balanced, factual, or shows no strong emotional content.\n",
    "\n",
    "Your response must only contain:\n",
    "\n",
    "1. **Sentiment:** One of the three labels â€“ `Positive`, `Negative`, or `Neutral`\n",
    "2. **Explanation:** A concise reason that supports the label, based only on emotional tone, word choice, or sentiment-laden phrases.\n",
    "\n",
    "You must not:\n",
    "- Provide summaries\n",
    "- Offer personal opinions\n",
    "- Evaluate content quality or logic\n",
    "- Infer intent beyond emotional expression\n",
    "\n",
    "Stick strictly to **sentiment analysis**.\n",
    "\n",
    "### Few-Shot Examples:\n",
    "\n",
    "1. **Text:** \"Absolutely love this app â€“ it's made my life so much easier!\"\n",
    "   **Sentiment:** Positive\n",
    "   **Explanation:** The phrase \"absolutely love\" strongly conveys enthusiasm and satisfaction.\n",
    "\n",
    "2. **Text:** \"I'm really disappointed with the service. It was slow and rude.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** Words like \"disappointed\", \"slow\", and \"rude\" clearly express dissatisfaction.\n",
    "\n",
    "3. **Text:** \"The package arrived on Tuesday as scheduled.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** This sentence is factual with no emotional language.\n",
    "\n",
    "4. **Text:** \"Not sure how I feel about this â€“ it's kind of a mixed bag.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** Ambiguous phrasing and lack of strong emotion suggest a neutral sentiment.\n",
    "\n",
    "5. **Text:** \"This is the worst experience I've had in months.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** The phrase \"worst experience\" indicates strong dissatisfaction.\n",
    "\n",
    "Now analyze the following text:\n",
    "\n",
    "**Text:** \"{text_input}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "   return generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4947842",
   "metadata": {},
   "source": [
    "#### Persuassion Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806e6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persuassion_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"You are a Persuasion Strategy Selector for a motor insurance dialogue system. \n",
    "   Based on the user's most recent utterance and the conversation history, you must recommend \n",
    "   the most suitable persuasion strategy the agent should use next to move the conversation forward and \n",
    "   help the user make a confident insurance decision.\n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "\n",
    "You must choose from the following six persuasion strategies, each defined with use cases and examples:\n",
    "\n",
    " Persuasion Strategies:\n",
    "Credibility Appeal\n",
    "Definition: Emphasize the insurance providerâ€™s reputation, trustworthiness, or long-standing service.\n",
    "Use when: The user is hesitant, asks about reliability, or mentions concern over service quality.\n",
    "Example:\n",
    "\"New India Assurance has one of the widest repair networks in India and a proven record of settling claims efficiently.\"\n",
    "\n",
    "Logical Appeal\n",
    "Definition: Use facts, comparisons, benefits, or pricing logic to persuade.\n",
    "Use when: The user is analytical, budget-conscious, or asking for details or comparisons.\n",
    "Example:\n",
    "\"HDFC ERGOâ€™s policy includes 24/7 support and zero-depreciation coverage, which means more savings during repairs.\"\n",
    "\n",
    "Persona-Based Appeal\n",
    "Definition: Match the policy features to the userâ€™s lifestyle, habits, or profile.\n",
    "Use when: The user reveals driving habits, tech-savviness, family needs, or risk aversion.\n",
    "Example:\n",
    "\"Since you often drive long distances, Tata AIGâ€™s Telematics-Based Monitoring suits your tech-savvy lifestyle.\"\n",
    "\n",
    "Emotional Appeal\n",
    "Definition: Tap into feelings like fear, safety, or care for loved ones.\n",
    "Use when: The user talks about family, emergencies, peace of mind, or personal safety.\n",
    "Example:\n",
    "\"Imagine a late-night breakdownâ€”our 24/7 roadside assistance gives you and your family peace of mind.\"\n",
    "\n",
    "Personal Appeal\n",
    "Definition: Use positive sentiment, social proof, or popularity of the plan.\n",
    "Use when: The user is unsure or looking for recommendations.\n",
    "Example:\n",
    "\"This plan is one of our most popular choicesâ€”users love the smooth claims experience.\"\n",
    "\n",
    "Default Persuasion Strategy\n",
    "Definition: Use when little context is available. Provide neutral, factual reassurance.\n",
    "Use when: The user is vague or hasnâ€™t revealed any preferences or concerns.\n",
    "Example:\n",
    "\"This policy offers protection against theft, accidents, and includes access to cashless repairs.\"\n",
    "\n",
    "Instructions:\n",
    "Given the current user utterance and the conversation history, perform the following:\n",
    "Suggest the next best strategy that could be used.\n",
    "Give a brief justification (1â€“2 lines max).\n",
    "\n",
    "And please be brief.\n",
    "\n",
    "\n",
    "\n",
    " Few-Shot Examples\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Is this company actually reliable when it comes to claims?\"\n",
    "Future Strategy: Credibility Appeal\n",
    "Justification: The user directly questions the insurerâ€™s reliability â€” trust needs to be reinforced.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"I travel a lot for work, so I need something flexible.\"\n",
    "Future Strategy: Persona-Based Appeal\n",
    "Justification: The user has revealed lifestyle habits that allow for a tailored recommendation.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"What does the policy cover exactly?\"\n",
    "Future Strategy: Logical Appeal\n",
    "Justification: The user is asking for objective, factual details.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"What if my car breaks down at night while Iâ€™m driving with my kids?\"\n",
    "Future Strategy: Emotional Appeal\n",
    "Justification: The user is expressing concern for family and emergency scenarios.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"Iâ€™m just looking for something people usually go for.\"\n",
    "Future Strategy: Personal Appeal\n",
    "Justification: The user is undecided and seeking reassurance based on othersâ€™ choices.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"Okay, what are the basic features?\"\n",
    "Future Strategy: Default Persuasion Strategy\n",
    "Justification: The user hasnâ€™t shared enough context â€” a neutral overview is appropriate.\n",
    "\n",
    "Output Format\n",
    "\n",
    "Future Strategy: [One of the six strategies]\n",
    "Justification: [1â€“2 line explanation]\n",
    "\n",
    "Here is my input:{text_input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46e362",
   "metadata": {},
   "source": [
    "#### Keyterm Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bcef885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyterms_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"You are a Keyterm Expert specializing in the motor insurance domain. \n",
    "   Your job is to analyze the userâ€™s most recent utterance, using the conversation history for context, \n",
    "   and identify one or more important motor insurance-related keyterms mentioned (explicitly or implicitly) by the user.\n",
    "\n",
    "\n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "These keyterms help the system focus the conversation, match features, and determine relevant coverages.\n",
    "\n",
    "Examples of Common Keyterms (but not limited to):\n",
    "Comprehensive coverage\n",
    "Third-party liability\n",
    "Roadside assistance\n",
    "Zero depreciation / depreciation\n",
    "Claim settlement\n",
    "Battery protection\n",
    "Own damage\n",
    "Add-on cover\n",
    "Telematics\n",
    "Engine protection\n",
    "EV (Electric Vehicle)\n",
    "Repair network\n",
    "Policy premium\n",
    "Cashless garages\n",
    "Deductibles\n",
    "Policy renewal\n",
    "Personal accident cover\n",
    "IDV (Insured Declared Value)\n",
    "\n",
    "You may also extract user-specific or vehicle-specific keyterms that are relevant to insurance decisions (e.g., â€œTesla Model 3,â€ â€œEV,â€ â€œ2024 vehicleâ€).\n",
    "\n",
    "Instructions:\n",
    "From the current user utterance (with conversation history for context), do the following:\n",
    "Extract all relevant keyterms mentioned or implied in the user's message.\n",
    "For each keyterm, provide a brief 1-line justification for why itâ€™s relevant in the motor insurance domain.\n",
    "\n",
    "Few-Shot Examples\n",
    "\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Whatâ€™s the premium for a 2024 Tesla Model 3?\"\n",
    "Extracted Keyterms: Policy premium, 2024 Tesla Model 3  \n",
    "Justification: The user is asking for a cost estimate tied to a specific vehicle, both of which are essential for determining appropriate motor insurance coverage and pricing.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"Does this plan include accident and theft protection?\"\n",
    "Extracted Keyterms: Comprehensive coverage  \n",
    "Justification: The user is inquiring about accident and theft protection, which are typically included under comprehensive coverage plans.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"What happens if my EV breaks down far from home?\"\n",
    "Extracted Keyterms: Roadside assistance, EV  \n",
    "Justification: The user is describing a breakdown scenario involving an electric vehicle, which is directly relevant to roadside assistance coverage for EVs.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"Does this cover things like roadside help if Iâ€™m stuck somewhere?\"\n",
    "Extracted Keyterm: Roadside assistance  \n",
    "Justification: The user is asking about support in case of breakdowns, which is typically handled under roadside assistance.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"I'm looking for something that includes coverage for theft and accidents.\"\n",
    "Extracted Keyterm: Comprehensive coverage  \n",
    "Justification: Coverage for both theft and accidents implies a comprehensive motor insurance policy.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"I want to make sure the battery is protectedâ€”itâ€™s the most expensive part of the car.\"\n",
    "Extracted Keyterm: Battery protection  \n",
    "Justification: The user expresses concern about the EV battery, which is typically covered under specific EV-related add-ons.\n",
    "\n",
    "Example 7\n",
    "User Utterance:\n",
    "\"Whatâ€™s the premium for a 2024 Tesla Model 3?\"\n",
    "Extracted Keyterm: Policy premium  \n",
    "Justification: The user is asking about cost, which relates directly to the insurance premium.  \n",
    ":\n",
    "Output Format\n",
    "For extracted keyterm, provide the following:\n",
    "Extracted Keyterm: [Term]  \n",
    "Justification: [Brief reason why it's relevant to motor insurance]\n",
    "\n",
    "Here is my input sentence:{text_input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ef089",
   "metadata": {},
   "source": [
    "#### Intern Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee0de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"You are an Intent Expert for a virtual assistant specializing in motor insurance.\n",
    "   Your job is to analyze the current user utterance, using the conversation history for context,\n",
    "   and determine the single most relevant intent expressed by the user.\n",
    "\n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "\n",
    "You must select from a fixed set of six pre-defined intents (listed below), each with clear definitions, examples, and triggers relevant to the motor insurance domain.\n",
    "\n",
    "ðŸŽ¯ Available Intents:\n",
    "Request_Insurance_Quote\n",
    "Definition: The user initiates interest in getting a motor insurance quote or policy.\n",
    "Example: \"Hi, I'm looking to get motor insurance for my Tesla Model 3.\"\n",
    "Trigger: User starts a new request related to getting insured.\n",
    "\n",
    "Ask_Coverage_Details\n",
    "Definition: The user asks about what types of protection the insurance provides, especially for specific parts (e.g., battery, accidents, theft).\n",
    "Example: \"What kind of coverage options do you have specifically for the battery?\"\n",
    "Trigger: User inquires about included benefits, policy terms, or protections.\n",
    "\n",
    "Express_Concern\n",
    "Definition: The user shares a specific concern or priority about what needs to be protected or covered.\n",
    "Example: \"Yes, battery protection is definitely a concern for me.\"\n",
    "Trigger: User highlights what matters most to them or expresses worry.\n",
    "\n",
    "Request_Additional_Info\n",
    "Definition: The user requests clarification or a deeper explanation of a feature or condition.\n",
    "Example: \"Do you cover accidents caused by the battery?\"\n",
    "Trigger: User follows up with questions or asks how something works.\n",
    "\n",
    "Confirm_Interest\n",
    "Definition: The user agrees, approves, or explicitly indicates they want to proceed.\n",
    "Example: \"That sounds good. Iâ€™d like to proceed.\"\n",
    "Trigger: User shows intent to buy, continue, or finalize the service.\n",
    "\n",
    "Ask_Price_or_Premium\n",
    "Definition: The user wants to know the cost or breakdown of the insurance premium.\n",
    "Example: \"How much would that cost?\"\n",
    "Trigger: User inquires about price, discounts, or cost factors.\n",
    "\n",
    "\n",
    "\n",
    "Instructions:\n",
    "Given the conversation history and the userâ€™s most recent message:\n",
    "Identify the intent most clearly reflected in the current user utterance, based on the above definitions.\n",
    "Provide a brief 1â€“2 line justification for your selection, grounded in the userâ€™s phrasing and conversational context.\n",
    "\n",
    "Few-Shot Examples\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Hi, I'm looking to get insurance for my new Tesla.\"\n",
    "Intent: Request_Insurance_Quote  \n",
    "Justification: The user is initiating a conversation to obtain motor insurance for a specific vehicle.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"Do you cover damage to the battery?\"\n",
    "Intent: Ask_Coverage_Details  \n",
    "Justification: The user is asking about a specific type of coverage related to their EV battery.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"Battery protection is definitely a concern for me.\"\n",
    "Intent: Express_Concern  \n",
    "Justification: The user is explicitly stating a personal worry or priority regarding coverage.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"Can you explain how the battery coverage works?\"\n",
    "Intent: Request_Additional_Info  \n",
    "Justification: The user is asking for clarification or further explanation of a feature already mentioned.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"That sounds good. Iâ€™m ready to go ahead.\"\n",
    "Intent: Confirm_Interest  \n",
    "Justification: The user is showing a clear desire to move forward with the policy or service.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"How much will that cost me annually?\"\n",
    "Intent: Ask_Price_or_Premium  \n",
    "Justification: The user is directly asking about the premium or cost of the insurance policy.\n",
    "\n",
    "Output Format\n",
    "\n",
    "Intent: [One of the six predefined intents]  \n",
    "Justification: [1â€“2 line explanation of why this intent matches the user's message]\n",
    "Here is my input:{text_input}\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c1201f",
   "metadata": {},
   "source": [
    "### Extra 5 tools as expert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb98a3",
   "metadata": {},
   "source": [
    "#### 1)NER & POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4ca574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56d7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# Load English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b6fe782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(sentence):\n",
    "    \"\"\"\n",
    "    Analyze a sentence for POS tagging and Named Entity Recognition,\n",
    "    and return the results as a formatted string.\n",
    "    \n",
    "    Parameters:\n",
    "    sentence (str): The input sentence to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    str: Formatted string with POS tags and Named Entities.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    result = []\n",
    "\n",
    "    # POS tagging\n",
    "    result.append(\"Part-of-Speech Tags:\")\n",
    "    for token in doc:\n",
    "        result.append(f\"{token.text} -> {token.pos_} ({token.tag_})\")\n",
    "\n",
    "    # Named Entity Recognition\n",
    "    result.append(\"\\nNamed Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        result.append(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "# analyze_text(\"I like cricket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b331d",
   "metadata": {},
   "source": [
    "#### 2) Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7050e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # For consistent results\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db4fbd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Detected language is: en'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        language= 'Detected language is: ' + language\n",
    "        return language\n",
    "    except:\n",
    "        return \"Could not detect language\"\n",
    "detect_language(\"This is an English sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5176ddda",
   "metadata": {},
   "source": [
    "#### 3) Dependency persing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdfe812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token        Dep          Head\n",
      "The          -> det          -> fox\n",
      "quick        -> amod         -> fox\n",
      "brown        -> amod         -> fox\n",
      "fox          -> nsubj        -> jumps\n",
      "jumps        -> ROOT         -> jumps\n",
      "over         -> prep         -> jumps\n",
      "the          -> det          -> dog\n",
      "lazy         -> amod         -> dog\n",
      "dog          -> pobj         -> over\n",
      ".            -> punct        -> jumps\n"
     ]
    }
   ],
   "source": [
    "def get_dependencies(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Build plain-text dependency list\n",
    "    lines = [\"Token        Dep          Head\"]\n",
    "    for token in doc:\n",
    "        lines.append(f\"{token.text:<12} -> {token.dep_:<12} -> {token.head.text}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Example usage\n",
    "output = get_dependencies(\"The quick brown fox jumps over the lazy dog.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32cf3f",
   "metadata": {},
   "source": [
    "#### 4)Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dd5dc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Relation: (I, buy, Classic)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_SVO_string(text):\n",
    "    \"\"\"\n",
    "    Extract (Subject, Verb, Object) triples from input text and return them as a formatted string.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input sentence or paragraph.\n",
    "\n",
    "    Returns:\n",
    "    str: SVO relations, one per line. Returns a message if no SVO found.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    triples = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ != \"VERB\":\n",
    "            continue\n",
    "\n",
    "        subjects = [w for w in token.lefts if w.dep_ in (\"nsubj\", \"nsubjpass\")]\n",
    "        if not subjects:\n",
    "            continue\n",
    "\n",
    "        objects = [w for w in token.rights if w.dep_ == \"dobj\"]\n",
    "\n",
    "        for prep in (w for w in token.rights if w.dep_ == \"prep\"):\n",
    "            objects.extend([w for w in prep.rights if w.dep_ == \"pobj\"])\n",
    "\n",
    "        objects.extend([w for w in token.rights if w.dep_ == \"attr\"])\n",
    "\n",
    "        if subjects and objects:\n",
    "            for s in subjects:\n",
    "                for o in objects:\n",
    "                    triples.append(f\"Relation: ({s.text}, {token.lemma_}, {o.text})\")\n",
    "\n",
    "    return \"\\n\".join(triples) if triples else \"No Subjectâ€“Verbâ€“Object relations found.\"\n",
    "\n",
    "# Example usage\n",
    "text = \"Hi, I am interested in getting motor insurance for my bike. I just bought a new 2024 Royal Enfield Classic 350.\"\n",
    "get_SVO_string(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab6acb",
   "metadata": {},
   "source": [
    "### Combine output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6123f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_analysis(\n",
    "    dialogue: str,\n",
    "    intent_output: str,\n",
    "    keyterms_output: str,\n",
    "    persuasion_output: str,\n",
    "    sentiment_output: str,\n",
    "    analyze_text_output: str,\n",
    "    language_output: str,\n",
    "    dependencies_output: str,\n",
    "    svo_output: str\n",
    ") -> str:\n",
    "\n",
    "    prompt = f\"\"\"You are an advanced language model trained to generate professional, helpful, and natural-sounding agent responses.  \n",
    "You receive internal insights from eight expert systems for a single user input:\n",
    "\n",
    "- Intent Expert: Understands what the user is trying to express or request  \n",
    "- Key Term Expert: Extracts main concepts and keywords  \n",
    "- Sentiment Expert: Evaluates the emotional tone (positive, negative, skeptical, etc.)  \n",
    "- Persuasion Expert: Identifies emotional or rhetorical tactics used  \n",
    "- analyze_text: Provides part-of-speech tags and named entities  \n",
    "- detect_language: Detects the user's input language  \n",
    "- get_dependencies: Analyzes sentence structure and word relationships  \n",
    "- get_SVO_string: Extracts subjectâ€“verbâ€“object relations (e.g., Relation: (user, wants, feature))\n",
    "\n",
    "Your task is to use **all expert insights** internally to craft one final, human-sounding response â€” **never repeat or explain the expert outputs**.\n",
    "\n",
    "### Agent Response Guidelines:\n",
    "- Be warm, empathetic, and respectful  \n",
    "- Acknowledge and validate the user's emotion or concern  \n",
    "- Offer context or clarity when helpful  \n",
    "- Never sound robotic, technical, or condescending  \n",
    "- Do not list points or restate expert content â€” just speak naturally\n",
    "\n",
    "â€“â€“â€“â€“ Few-Shot Examples â€“â€“â€“â€“\n",
    "\n",
    "Example 1  \n",
    "Dialogue: \"I think electric cars are overrated and not really helping the environment.\"  \n",
    "Intent: Opinion  \n",
    "Keyterms: \"electric cars\", \"overrated\", \"helping the environment\"  \n",
    "Sentiment: Skeptical  \n",
    "Persuasion: Generalization  \n",
    "analyze_text:  \n",
    "Part-of-Speech Tags:\\nI -> PRON (PRP)\\nthink -> VERB (VBP)\\nelectric -> ADJ (JJ)...  \n",
    "Named Entities: None  \n",
    "get_SVO_string: Relation: (cars, are, overrated)  \n",
    "\n",
    "Response:  \n",
    "Thank you for sharing your view â€” itâ€™s completely valid to question the impact of electric vehicles. While no solution is perfect, many studies show EVs tend to produce fewer emissions over time, especially when powered by renewables.\n",
    "\n",
    "---\n",
    "\n",
    "Example 2  \n",
    "Dialogue: \"AI is going to take over every job and make humans useless.\"  \n",
    "Intent: Expressing concern  \n",
    "Keyterms: \"AI\", \"every job\", \"humans useless\"  \n",
    "Sentiment: Negative  \n",
    "Persuasion: Exaggeration  \n",
    "detect_language: English  \n",
    "get_SVO_string: Relation: (AI, take over, job)  \n",
    "\n",
    "Response:  \n",
    "I understand how that sounds â€” AIâ€™s progress can feel overwhelming. But rather than replacing people, itâ€™s often designed to work alongside us, creating new kinds of jobs and ways of working that didnâ€™t exist before.\n",
    "\n",
    "---\n",
    "\n",
    "Example 3  \n",
    "Dialogue: \"Can you guys add dark mode to the settings?\"  \n",
    "Intent: Feature request  \n",
    "Keyterms: \"dark mode\", \"settings\"  \n",
    "Sentiment: Neutral  \n",
    "analyze_text:  \n",
    "Part-of-Speech Tags:\\nCan -> AUX (MD)\\nyou -> PRON (PRP)\\nguys -> NOUN (NNS)\\nadd -> VERB (VB)...  \n",
    "get_SVO_string: Relation: (you, add, dark mode)  \n",
    "\n",
    "Response:  \n",
    "Thanks for the suggestion â€” dark mode is a popular request and makes a lot of sense. Iâ€™ll pass this along to our team for consideration.\n",
    "\n",
    "---\n",
    "\n",
    "Now generate a final, agent-like response for the following input.  \n",
    "Use all expert insights provided, but **do not include or reference them** directly. Only output the final response.\n",
    "\n",
    "Dialogue: \"{dialogue}\"  \n",
    "Intent: {intent_output}  \n",
    "Keyterms: {keyterms_output}  \n",
    "Persuasion: {persuasion_output}  \n",
    "Sentiment: {sentiment_output}  \n",
    "analyze_text: {analyze_text_output}  \n",
    "detect_language: {language_output}  \n",
    "get_dependencies: {dependencies_output}  \n",
    "get_SVO_string: {svo_output}  \n",
    "\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "    return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2728ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataset():\n",
    "\n",
    "    # Make sure your CSV has the columns: 'conversation_id', 'turn_no', 'utterance', 'new_agent_reply'\n",
    "    df = pd.read_csv('/home/rohank__iitp/Work/niladri/baselines dataset/new_dataset_conversation.csv')\n",
    "    # --- Response Generation and Incremental Saving ---\n",
    "\n",
    "    if not df.empty:\n",
    "        output_filename = '/home/rohank__iitp/Work/niladri/baselines dataset/qween/allexp/qween_allexp_dataset.csv'\n",
    "        header_written = False\n",
    "        \n",
    "        # Group by conversation_id to process one conversation at a time\n",
    "        grouped = df.groupby('conversation_id')\n",
    "\n",
    "        for conversation_id, group in grouped:\n",
    "            print(f\"\\nProcessing Conversation ID: {conversation_id}\")\n",
    "            \n",
    "            # Ensure the conversation turns are in chronological order\n",
    "            group = group.sort_values('turn_no')\n",
    "            conversation_history = \"\"\n",
    "            processed_rows = []\n",
    "\n",
    "            for index, row in group.iterrows():\n",
    "                # Construct the prompt with the history plus the current user utterance\n",
    "                sentence = \"Conversation History:\\n\" + conversation_history + \"Current Utterance: \" + f\"User: {row['utterance']}\\nAgent:\"\n",
    "                # Your debugging print statements\n",
    "                print(\"========================================================================================================================================\")\n",
    "                print(f\"Generating for conv_id: {row['conversation_id']}, turn: {row['turn_no']}\\nPROMPT:\\n{sentence}\")\n",
    "                print(\"========================================================================================================================================\")\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Generate the response\n",
    "                '''Change HereðŸ˜†ðŸ˜†ðŸ˜†ðŸ˜†'''\n",
    "                \n",
    "                # qwen_response = process_input_with_selector_model(prompt)\n",
    "                persuasion_output=persuassion_expert(sentence)\n",
    "                sentiment_output = sentiment_expert(sentence)\n",
    "                keyterms_output = keyterms_expert(sentence)\n",
    "                intent_output = intent_expert(sentence)\n",
    "                \n",
    "                #new expert tools\n",
    "                analyze_text_output = analyze_text(sentence)\n",
    "                detect_language_output = detect_language(sentence)\n",
    "                get_dependencies_output = get_dependencies(sentence)\n",
    "                get_SVO_output = get_SVO_string(sentence)\n",
    "                \n",
    "                qwen_response = generate_combined_analysis(\n",
    "                dialogue=sentence,\n",
    "                intent_output=intent_output,\n",
    "                keyterms_output=keyterms_output,\n",
    "                persuasion_output=persuasion_output,\n",
    "                sentiment_output=sentiment_output,\n",
    "                analyze_text_output=analyze_text_output,\n",
    "                language_output=detect_language_output,\n",
    "                dependencies_output=get_dependencies_output,\n",
    "                svo_output=get_SVO_output)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Create a dictionary from the original row and add the new response\n",
    "                current_row_data = row.to_dict()\n",
    "                current_row_data['Qween Allexp Response'] = qwen_response\n",
    "                processed_rows.append(current_row_data)\n",
    "\n",
    "                # Update the history for the next turn in this conversation\n",
    "                conversation_history += f\"User: {row['utterance']}\\nAgent: {row['new_agent_reply']}\\n\"\n",
    "            \n",
    "            # Create a DataFrame for the just-processed conversation\n",
    "            processed_group_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "            # Append the processed conversation to the output CSV file\n",
    "            if not header_written:\n",
    "                # For the first conversation, write with header and overwrite the file\n",
    "                processed_group_df.to_csv(output_filename, index=False, mode='w')\n",
    "                header_written = True\n",
    "            else:\n",
    "                # For subsequent conversations, append without the header\n",
    "                processed_group_df.to_csv(output_filename, index=False, mode='a', header=False)\n",
    "            \n",
    "            print(f\"Conversation ID {conversation_id} has been processed and saved.\")\n",
    "\n",
    "        print(f\"\\nProcessing complete. All conversations have been saved to '{output_filename}'\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nDataFrame is empty. No responses were generated or saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8551738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Starting dataset creation...\")\n",
    "start_time = time.time()\n",
    "print(\"Started at--->\", start_time)\n",
    "create_dataset()\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "print(\"Finished time\", end_time)\n",
    "\n",
    "# Print elapsed time\n",
    "print(f\"hey() completed in {end_time - start_time:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
