{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 46\n",
      "Rows after filtering: 43\n",
      "Cleaned file written to: /home/rohank__iitp/Work/niladri/dataset3/conversation.csv\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 1️⃣ ── LOAD YOUR DATA ────────────────────────────────────────────────────────\n",
    "# # Replace the file name/path as needed\n",
    "# infile  = \"/home/rohank__iitp/Work/niladri/dataset3/11conversation.csv\"\n",
    "# outfile = \"/home/rohank__iitp/Work/niladri/dataset3/conversation.csv\"\n",
    "\n",
    "# df = pd.read_csv(infile)\n",
    "\n",
    "# # 2️⃣ ── MAKE SURE THE DATA ARE IN TURN ORDER ────────────────────────────────\n",
    "# df = df.sort_values([\"conversation_id\", \"turn_no\"]).reset_index(drop=True)\n",
    "\n",
    "# # 3️⃣ ── IDENTIFY WHICH USER ROWS TO KEEP ─────────────────────────────────────\n",
    "# # Shift the Speaker and Conversation_id columns “up” one row\n",
    "# df[\"next_speaker\"] = df[\"speaker\"].shift(-1)\n",
    "# df[\"next_conv\"]    = df[\"conversation_id\"].shift(-1)\n",
    "\n",
    "# # User rows we **want to keep** are those whose next row\n",
    "# #  • is from the SAME conversation and\n",
    "# #  • has Speaker == \"Agent\"\n",
    "# mask_user_keep = (\n",
    "#     (df[\"speaker\"] == \"User\") &\n",
    "#     (df[\"next_conv\"] == df[\"conversation_id\"]) &\n",
    "#     (df[\"next_speaker\"] == \"Agent\")\n",
    "# )\n",
    "\n",
    "# # Agent rows are always kept\n",
    "# mask_agent_keep = df[\"speaker\"] == \"Agent\"\n",
    "\n",
    "# # Combine the two conditions\n",
    "# mask_keep = mask_agent_keep | mask_user_keep\n",
    "\n",
    "# # 4️⃣ ── FILTER & SAVE ────────────────────────────────────────────────────────\n",
    "# filtered_df = df[mask_keep].drop(columns=[\"next_speaker\", \"next_conv\"])\n",
    "# filtered_df.to_csv(outfile, index=False)\n",
    "\n",
    "# print(f\"Original rows: {len(df)}\")\n",
    "# print(f\"Rows after filtering: {len(filtered_df)}\")\n",
    "# print(f\"Cleaned file written to: {outfile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6db0054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original CSV file\n",
    "df = pd.read_csv(\"/home/rohank__iitp/Work/niladri/dataset3/conversation.csv\")  # replace with actual path if not in current directory\n",
    "\n",
    "# Prepare variables\n",
    "output_rows = []\n",
    "agent_responses = []\n",
    "\n",
    "# Temporary variables to track user query and agent reply\n",
    "current_user_query = None\n",
    "current_conversation_id = None\n",
    "record_id = 1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['speaker'] == 'User':\n",
    "        agent_responses.append(row['id'])\n",
    "        if current_user_query is not None:\n",
    "            # Save previous user query without agent reply\n",
    "            output_rows.append({\n",
    "                'id': record_id,\n",
    "                'conversation_id': current_conversation_id,\n",
    "                'user_query': current_user_query,\n",
    "                'agent_reply': ''\n",
    "            })\n",
    "            record_id += 1\n",
    "        # Start new user query\n",
    "        current_user_query = row['utterance']\n",
    "        current_conversation_id = row['conversation_id']\n",
    "    elif row['speaker'] == 'Agent':\n",
    "        \n",
    "        if current_user_query is not None:\n",
    "            # agent_responses.append(row['id'])\n",
    "            # Save user query and agent reply\n",
    "            output_rows.append({\n",
    "                'id': record_id,\n",
    "                'conversation_id': current_conversation_id,\n",
    "                'user_query': current_user_query,\n",
    "                'agent_reply': row['utterance']\n",
    "            })\n",
    "            record_id += 1\n",
    "            current_user_query = None  # Reset after pairing\n",
    "\n",
    "# If last entry is a user query without an agent reply\n",
    "if current_user_query is not None:\n",
    "    output_rows.append({\n",
    "        'id': record_id,\n",
    "        'conversation_id': current_conversation_id,\n",
    "        'user_query': current_user_query,\n",
    "        'agent_reply': ''\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv(\"/home/rohank__iitp/Work/niladri/dataset3/allexp/table_allexp.csv\", index=False)\n",
    "\n",
    "# Print or return list of agent responses\n",
    "print(agent_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "465bfafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f96c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the CSV file\n",
    "# df = pd.read_csv('/home/rohank__iitp/Work/niladri/dataset3/allexp/table_allexp.csv')\n",
    "\n",
    "# # Drop rows where 'agent_reply' is NaN or an empty string\n",
    "# df_cleaned = df[df['agent_reply'].notna() & (df['agent_reply'].str.strip() != '')]\n",
    "\n",
    "# # Save the cleaned DataFrame to a new CSV (or overwrite the original)\n",
    "# df_cleaned.to_csv('/home/rohank__iitp/Work/niladri/dataset3/allexp/table_allexp.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c77648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df=pd.read_csv(\"/home/rohank__iitp/Work/niladri/dataset3/allexp/table_allexp.csv\")  # replace with actual path if not in current directory\n",
    "# Output list for matching answers\n",
    "matching_answers = []\n",
    "\n",
    "# Read and process the JSONL file\n",
    "with open('/home/rohank__iitp/Work/niladri/dataset3/allexp/cleaned_output.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        # if data.get('id_json') in agent_responses:\n",
    "        matching_answers.append(data.get('answer'))\n",
    "\n",
    "df[\"all expterts response\"]= matching_answers\n",
    "df.to_csv(\"/home/rohank__iitp/Work/niladri/dataset3/allexp/table_allexp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f14cc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/DATA/rohan_kirti/.local/lib/python3.8/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03fbbc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "594623be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"/home/rohank__iitp/Work/niladri/dataset3/allexp/table_allexp.csv\")  # Replace with your actual file path\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "\n",
    "# Compute ROUGE scores\n",
    "def compute_rouge(row):\n",
    "    scores = scorer.score(row['all expterts response'], row['agent_reply'])\n",
    "    return scores['rouge1'].fmeasure  # You can also use .precision or .recall\n",
    "\n",
    "# Apply ROUGE calculation\n",
    "df['rouge'] = df.apply(compute_rouge, axis=1)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(\"/home/rohank__iitp/Work/niladri/dataset3/allexp/table_allexp.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
