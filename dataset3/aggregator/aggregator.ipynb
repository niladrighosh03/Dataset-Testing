{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df226245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d1152fe161465092a13b5440af61d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"/scratch/rohank__iitp/qwen2_5_7b_instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bf0ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". Sure, I can help you with that! As of my last update, specific details on the exact insurance cost for the Tesla Model 3 in India are not readily available as they can vary based on several factors such as:\n",
      "\n",
      "1. **Car Configuration**: The type of Model 3 you choose (Standard Range, Long Range, etc.) and its features.\n",
      "2. **Insurance Type**: Whether it's a comprehensive or third-party insurance policy.\n",
      "3. **Location**: Where you live in India\n"
     ]
    }
   ],
   "source": [
    "def generate(prompt:str):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_length = inputs['input_ids'].shape[1]\n",
    "    # Generate text\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Decode and print response\n",
    "    generated_tokens = outputs[0][input_length:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "x=generate(\"I need the information about tesla 3 model insurance cost in india\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cde079",
   "metadata": {},
   "source": [
    "#### Persuassion expert (Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b04f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"\n",
    "You are an AI trained to act solely as a **sentiment expert**. Your job is to analyze the **emotional tone** of the input text and classify it into one of the following three categories:\n",
    "\n",
    "- **Positive** – The text expresses happiness, satisfaction, excitement, appreciation, or any other positive emotion.\n",
    "- **Negative** – The text expresses disappointment, frustration, anger, sadness, criticism, or other negative feelings.\n",
    "- **Neutral** – The text is emotionally balanced, factual, or shows no strong emotional content.\n",
    "\n",
    "Your response must only contain:\n",
    "\n",
    "1. **Sentiment:** One of the three labels – `Positive`, `Negative`, or `Neutral`\n",
    "2. **Explanation:** A concise reason that supports the label, based only on emotional tone, word choice, or sentiment-laden phrases.\n",
    "\n",
    "You must not:\n",
    "- Provide summaries\n",
    "- Offer personal opinions\n",
    "- Evaluate content quality or logic\n",
    "- Infer intent beyond emotional expression\n",
    "\n",
    "Stick strictly to **sentiment analysis**.\n",
    "\n",
    "### Few-Shot Examples:\n",
    "\n",
    "1. **Text:** \"Absolutely love this app – it's made my life so much easier!\"\n",
    "   **Sentiment:** Positive\n",
    "   **Explanation:** The phrase \"absolutely love\" strongly conveys enthusiasm and satisfaction.\n",
    "\n",
    "2. **Text:** \"I'm really disappointed with the service. It was slow and rude.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** Words like \"disappointed\", \"slow\", and \"rude\" clearly express dissatisfaction.\n",
    "\n",
    "3. **Text:** \"The package arrived on Tuesday as scheduled.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** This sentence is factual with no emotional language.\n",
    "\n",
    "4. **Text:** \"Not sure how I feel about this – it's kind of a mixed bag.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** Ambiguous phrasing and lack of strong emotion suggest a neutral sentiment.\n",
    "\n",
    "5. **Text:** \"This is the worst experience I've had in months.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** The phrase \"worst experience\" indicates strong dissatisfaction.\n",
    "\n",
    "Now analyze the following text:\n",
    "\n",
    "**Text:** \"{text_input}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "   return generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4947842",
   "metadata": {},
   "source": [
    "#### Persuassion Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806e6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persuassion_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"\n",
    "You are an AI trained to act solely as a **sentiment expert**. Your job is to analyze the **emotional tone** of the input text and classify it into one of the following three categories:\n",
    "\n",
    "- **Positive** – The text expresses happiness, satisfaction, excitement, appreciation, or any other positive emotion.\n",
    "- **Negative** – The text expresses disappointment, frustration, anger, sadness, criticism, or other negative feelings.\n",
    "- **Neutral** – The text is emotionally balanced, factual, or shows no strong emotional content.\n",
    "\n",
    "Your response must only contain:\n",
    "\n",
    "1. **Sentiment:** One of the three labels – `Positive`, `Negative`, or `Neutral`\n",
    "2. **Explanation:** A concise reason that supports the label, based only on emotional tone, word choice, or sentiment-laden phrases.\n",
    "\n",
    "You must not:\n",
    "- Provide summaries\n",
    "- Offer personal opinions\n",
    "- Evaluate content quality or logic\n",
    "- Infer intent beyond emotional expression\n",
    "\n",
    "Stick strictly to **sentiment analysis**.\n",
    "\n",
    "### Few-Shot Examples:\n",
    "\n",
    "1. **Text:** \"Absolutely love this app – it's made my life so much easier!\"\n",
    "   **Sentiment:** Positive\n",
    "   **Explanation:** The phrase \"absolutely love\" strongly conveys enthusiasm and satisfaction.\n",
    "\n",
    "2. **Text:** \"I'm really disappointed with the service. It was slow and rude.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** Words like \"disappointed\", \"slow\", and \"rude\" clearly express dissatisfaction.\n",
    "\n",
    "3. **Text:** \"The package arrived on Tuesday as scheduled.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** This sentence is factual with no emotional language.\n",
    "\n",
    "4. **Text:** \"Not sure how I feel about this – it's kind of a mixed bag.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** Ambiguous phrasing and lack of strong emotion suggest a neutral sentiment.\n",
    "\n",
    "5. **Text:** \"This is the worst experience I've had in months.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** The phrase \"worst experience\" indicates strong dissatisfaction.\n",
    "\n",
    "Now analyze the following text:\n",
    "\n",
    "**Text:** \"{text_input}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "   return generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46e362",
   "metadata": {},
   "source": [
    "#### Keyterm Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bcef885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyterms_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"\n",
    "You are a **Keyterm Expert**. Your job is to extract the most important **key terms or phrases** from the input text. These terms should:\n",
    "\n",
    "- Reflect the **core concepts**, **entities**, **topics**, or **important actions** in the text.\n",
    "- Be **noun phrases**, **domain-specific vocabulary**, or **verb-based actions** relevant to the subject.\n",
    "\n",
    "You must **not**:\n",
    "- Summarize the text\n",
    "- Explain or describe the text\n",
    "- Output full sentences\n",
    "\n",
    "Your response must include only a list of **key terms or phrases**, separated by commas.\n",
    "\n",
    "### Few-Shot Examples:\n",
    "\n",
    "1. **Text:** \"Artificial intelligence is transforming industries like healthcare, finance, and education by automating tasks and providing data-driven insights.\"\n",
    "   **Key Terms:** Artificial intelligence, healthcare, finance, education, automating tasks, data-driven insights\n",
    "\n",
    "2. **Text:** \"The Amazon rainforest, often referred to as the lungs of the Earth, is being threatened by illegal logging and wildfires.\"\n",
    "   **Key Terms:** Amazon rainforest, lungs of the Earth, illegal logging, wildfires\n",
    "\n",
    "3. **Text:** \"Quantum computing uses principles of superposition and entanglement to perform complex calculations much faster than classical computers.\"\n",
    "   **Key Terms:** Quantum computing, superposition, entanglement, complex calculations, classical computers\n",
    "\n",
    "Now extract the key terms from the following text:\n",
    "\n",
    "**Text:** \"{text_input}\"\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ef089",
   "metadata": {},
   "source": [
    "#### Intern Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee0de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"\n",
    "You are an **Intent Expert**. Your task is to analyze the user’s input and identify the **underlying intent** – what the person is trying to do, ask, or achieve with the message.\n",
    "\n",
    "Intent should be classified in the form of **short, action-oriented phrases** such as:\n",
    "- \"ask a question\"\n",
    "- \"make a complaint\"\n",
    "- \"request help\"\n",
    "- \"give feedback\"\n",
    "- \"express gratitude\"\n",
    "- \"seek information\"\n",
    "- \"report an issue\"\n",
    "- \"make a purchase inquiry\"\n",
    "\n",
    "You must provide:\n",
    "\n",
    "1. **Intent:** A concise label summarizing the user's goal  \n",
    "2. **Explanation:** A short justification based solely on the user’s wording or phrasing\n",
    "\n",
    "You must **not**:\n",
    "- Provide summaries\n",
    "- Infer sentiment unless directly related to intent\n",
    "- Rewrite or rephrase the input\n",
    "\n",
    "Focus only on what the user is trying to achieve.\n",
    "\n",
    "### Few-Shot Examples:\n",
    "\n",
    "1. **Text:** \"Can you help me reset my password?\"  \n",
    "   **Intent:** request help  \n",
    "   **Explanation:** The user is directly asking for assistance with resetting their password.\n",
    "\n",
    "2. **Text:** \"This app keeps crashing every time I open it.\"  \n",
    "   **Intent:** report an issue  \n",
    "   **Explanation:** The user is describing a recurring problem with the app.\n",
    "\n",
    "3. **Text:** \"Is there a student discount available for this software?\"  \n",
    "   **Intent:** ask a question  \n",
    "   **Explanation:** The user is seeking information about discounts.\n",
    "\n",
    "4. **Text:** \"Thanks so much for the quick response!\"  \n",
    "   **Intent:** express gratitude  \n",
    "   **Explanation:** The user is showing appreciation using thankful language.\n",
    "\n",
    "5. **Text:** \"I’m interested in subscribing to your premium plan.\"  \n",
    "   **Intent:** make a purchase inquiry  \n",
    "   **Explanation:** The user is expressing interest in a paid product or service.\n",
    "\n",
    "Now identify the intent for the following text:\n",
    "\n",
    "**Text:** \"{text_input}\"\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9db95",
   "metadata": {},
   "source": [
    "### Extra 5 tools as expert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271e86e",
   "metadata": {},
   "source": [
    "#### 1)NER & POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b84863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b4ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# Load English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906274e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(sentence):\n",
    "    \"\"\"\n",
    "    Analyze a sentence for POS tagging and Named Entity Recognition,\n",
    "    and return the results as a formatted string.\n",
    "    \n",
    "    Parameters:\n",
    "    sentence (str): The input sentence to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    str: Formatted string with POS tags and Named Entities.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    result = []\n",
    "\n",
    "    # POS tagging\n",
    "    result.append(\"Part-of-Speech Tags:\")\n",
    "    for token in doc:\n",
    "        result.append(f\"{token.text} -> {token.pos_} ({token.tag_})\")\n",
    "\n",
    "    # Named Entity Recognition\n",
    "    result.append(\"\\nNamed Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        result.append(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "# analyze_text(\"I like cricket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a8ec1",
   "metadata": {},
   "source": [
    "#### 2) Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a172244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # For consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c69845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Detected language is: en'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        language= 'Detected language is: ' + language\n",
    "        return language\n",
    "    except:\n",
    "        return \"Could not detect language\"\n",
    "detect_language(\"This is an English sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822a402",
   "metadata": {},
   "source": [
    "#### 3) Dependency persing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Uncomment the next line if you need the HTML visualization string\n",
    "# from spacy import displacy  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61856991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token        Dep          Head\n",
      "The          -> det          -> fox\n",
      "quick        -> amod         -> fox\n",
      "brown        -> amod         -> fox\n",
      "fox          -> nsubj        -> jumps\n",
      "jumps        -> ROOT         -> jumps\n",
      "over         -> prep         -> jumps\n",
      "the          -> det          -> dog\n",
      "lazy         -> amod         -> dog\n",
      "dog          -> pobj         -> over\n",
      ".            -> punct        -> jumps\n"
     ]
    }
   ],
   "source": [
    "def get_dependencies(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Build plain-text dependency list\n",
    "    lines = [\"Token        Dep          Head\"]\n",
    "    for token in doc:\n",
    "        lines.append(f\"{token.text:<12} -> {token.dep_:<12} -> {token.head.text}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Example usage\n",
    "output = get_dependencies(\"The quick brown fox jumps over the lazy dog.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54445c9",
   "metadata": {},
   "source": [
    "#### 4)Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d5cdf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Relation: (I, buy, Classic)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_SVO_string(text):\n",
    "    \"\"\"\n",
    "    Extract (Subject, Verb, Object) triples from input text and return them as a formatted string.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input sentence or paragraph.\n",
    "\n",
    "    Returns:\n",
    "    str: SVO relations, one per line. Returns a message if no SVO found.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    triples = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ != \"VERB\":\n",
    "            continue\n",
    "\n",
    "        subjects = [w for w in token.lefts if w.dep_ in (\"nsubj\", \"nsubjpass\")]\n",
    "        if not subjects:\n",
    "            continue\n",
    "\n",
    "        objects = [w for w in token.rights if w.dep_ == \"dobj\"]\n",
    "\n",
    "        for prep in (w for w in token.rights if w.dep_ == \"prep\"):\n",
    "            objects.extend([w for w in prep.rights if w.dep_ == \"pobj\"])\n",
    "\n",
    "        objects.extend([w for w in token.rights if w.dep_ == \"attr\"])\n",
    "\n",
    "        if subjects and objects:\n",
    "            for s in subjects:\n",
    "                for o in objects:\n",
    "                    triples.append(f\"Relation: ({s.text}, {token.lemma_}, {o.text})\")\n",
    "\n",
    "    return \"\\n\".join(triples) if triples else \"No Subject–Verb–Object relations found.\"\n",
    "\n",
    "# Example usage\n",
    "text = \"Hi, I am interested in getting motor insurance for my bike. I just bought a new 2024 Royal Enfield Classic 350.\"\n",
    "get_SVO_string(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030a32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def convert_structured_to_jsonl(text_block: str, i: int) -> str:\n",
    "    # dialogue_match = re.search(r\"<dialogue>\\s*(.*?)\\s*</dialogue>\", text_block, re.DOTALL)\n",
    "    # reasoning_match = re.search(r\"<reasoning>\\s*(.*?)\\s*</reasoning>\", text_block, re.DOTALL)\n",
    "    # answer_match = re.search(r\"answer\\s*(.*?)\\s*</answer>\", text_block, re.DOTALL)\n",
    "\n",
    "    # if not (dialogue_match and reasoning_match and answer_match):\n",
    "    #     raise ValueError(\"Could not find all required tags in the text.\")\n",
    "    # dialogue = dialogue_match.group(1).strip()\n",
    "    # reasoning = reasoning_match.group(1).strip()\n",
    "    # answer = answer_match.group(1).strip()\n",
    "\n",
    "    data = {\n",
    "        \"id_json\":i,\n",
    "\n",
    "        \"answer\": text_block.strip()\n",
    "    }\n",
    "\n",
    "    res=json.dumps(data)\n",
    "    with open(\"/home/rohank__iitp/Work/niladri/dataset3/aggregator/aggregator_response.jsonl\", \"a\") as f:\n",
    "        f.write(res + \"\\n\")\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d86ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "def csv_load(i:int):\n",
    "    file_path = '/home/rohank__iitp/Work/niladri/dataset3/conversation.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    conv_id = i\n",
    "    df = df[df['conversation_id'] == conv_id]\n",
    "\n",
    "    # Sort by turn number to ensure correct sequence\n",
    "    df.sort_values(by=\"turn_no\", inplace=True)\n",
    "\n",
    "    # Prepare conversation history\n",
    "    history = []\n",
    "    result = []\n",
    "\n",
    "    # Iterate through each row except the last one\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        speaker = row['speaker']\n",
    "        utterance = row['utterance']\n",
    "\n",
    "        # Add current cumulative history to result before appending new utterance\n",
    "        # result.append(\" \".join(history))\n",
    "\n",
    "        # Add current utterance with speaker label to history\n",
    "        result.append(f\"{speaker}: {utterance}\")\n",
    "\n",
    "    # Add the last utterance in the specified format\n",
    "    # last_utterance = df.iloc[-1]['utterance']\n",
    "    # result.append(f\"current utterance: {last_utterance}\")\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b4aa9",
   "metadata": {},
   "source": [
    "### 3 Agreegator  expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Router Function ----------\n",
    "def route_experts(sentence: str) -> list:\n",
    "    prompt = f\"\"\"\n",
    "You are a well-trained expert selector.\n",
    "Your job is to analyze the input sentence and determine which of the following expert modules are required.\n",
    "\n",
    "You MUST choose from the following list:\n",
    "1 Intent Expert  \n",
    "2 Keyterm Expert  \n",
    "3 Persuasion Expert  \n",
    "4 Sentiment Expert  \n",
    "5 analyze_text  \n",
    "6 detect_language  \n",
    "7 get_dependencies  \n",
    "8 get_SVO_string  \n",
    "\n",
    "You may select 1, several, or all 8 — but only those that are clearly needed based on the text.\n",
    "\n",
    "Always respond in **this below exact format**:\n",
    "Input: [original sentence]  \n",
    "Selected Experts: [Expert1, Expert2, etc]  \n",
    "Reason: [one sentence explaining why those experts were selected]\n",
    "\n",
    "Below are few-shot examples to help you understand the format and reasoning:\n",
    "\n",
    "Example #1  \n",
    "Input: Can someone please help me reset my password?  \n",
    "Selected Experts: [Intent Expert, Keyterm Expert]  \n",
    "Reason: The sentence expresses a help request (intent) and refers to a specific technical issue (keyterm).\n",
    "\n",
    "Example #2  \n",
    "Input: This app is a complete disaster. It crashes every time I try to open it.  \n",
    "Selected Experts: [Intent Expert, Sentiment Expert, Keyterm Expert, analyze_text, get_SVO_string]  \n",
    "Reason: This is a complaint (intent), shows strong negative emotion (sentiment), mentions technical terms (keyterm), and contains structured syntax that benefits from text analysis and relation extraction.\n",
    "\n",
    "Example #3  \n",
    "Input: Reset password link not working again.  \n",
    "Selected Experts: [Keyterm Expert, analyze_text]  \n",
    "Reason: The sentence includes factual technical content and benefits from part-of-speech analysis.\n",
    "\n",
    "Example #4  \n",
    "Input: I love how smooth the new interface feels – you guys nailed it!  \n",
    "Selected Experts: [Sentiment Expert, Persuasion Expert, analyze_text]  \n",
    "Reason: The sentence conveys positive emotion (sentiment), contains praise (persuasion), and has linguistic features worth analyzing.\n",
    "\n",
    "### Now process the following:\n",
    "Input: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = generate(prompt)\n",
    "\n",
    "        # response = model.generate_content(prompt).text.strip()\n",
    "        selected_experts = []\n",
    "\n",
    "        # Try regex to match the experts list\n",
    "        match = re.search(r\"Selected Experts:\\s*\\[(.*?)\\]\", response)\n",
    "        if match:\n",
    "            items = match.group(1).split(',')\n",
    "            selected_experts = [item.strip().strip('\"\\'').lower() for item in items if item.strip()]\n",
    "\n",
    "        return selected_experts\n",
    "    except Exception as e:\n",
    "        print(\"Error routing experts:\", e)\n",
    "        return []\n",
    "    prompt = f\"\"\"\n",
    "You are a well-trained expert selector.\n",
    "Your job is to analyze a given input sentence and decide which expert modules should be activated, based on what the speaker is expressing or trying to do.\n",
    "\n",
    "Available experts:\n",
    "- Intent Expert: For purpose, request, question, or user goal\n",
    "- Keyterm Expert: For extracting topic-specific or important terms\n",
    "- Persuasion Expert: For emotional, persuasive, or rhetorical language\n",
    "- Sentiment Expert: For emotional tone (positive, negative, or neutral)\n",
    "\n",
    "Select ONLY the necessary experts based on content. Return 1, 2, 3, or 4 depending on relevance. Do NOT include experts unnecessarily.\n",
    "\n",
    "### Output Format\n",
    "Input: [sentence]\n",
    "Selected Experts: [Expert1, Expert2, ...]\n",
    "Reason: [Short explanation]\n",
    "\n",
    "### Examples\n",
    "\n",
    "Input: Can someone please help me reset my password?\n",
    "Selected Experts: [Intent Expert, Keyterm Expert]\n",
    "Reason: Request for help (intent), contains topic terms (\"reset password\")\n",
    "\n",
    "Input: This app is a complete disaster. It crashes every time I try to open it.\n",
    "Selected Experts: [Intent Expert, Sentiment Expert, Keyterm Expert]\n",
    "Reason: Complaint (intent), frustration (sentiment), key terms mentioned\n",
    "\n",
    "Input: Reset password link not working again.\n",
    "Selected Experts: [Keyterm Expert]\n",
    "Reason: Technical/factual content only\n",
    "\n",
    "Input: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "    # Generate response\n",
    "\n",
    "    response = generate(prompt)\n",
    "\n",
    "    # Extract list from \"Selected Experts:\"\n",
    "    selected_experts = []\n",
    "    for line in response.splitlines():\n",
    "        if line.startswith(\"Selected Experts:\"):\n",
    "            try:\n",
    "                raw = line.split(\":\", 1)[1].strip()\n",
    "                expert_list = eval(raw)  # turns '[Intent Expert, Keyterm Expert]' into list\n",
    "                selected_experts = [e.lower() for e in expert_list]\n",
    "            except:\n",
    "                pass\n",
    "            break\n",
    "\n",
    "    return selected_experts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- 3 Aggregation Function ----------\n",
    "def generate_combined_analysis1(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    prompt = f\"\"\"You are a trained virtual support agent.\n",
    "\n",
    "Your role is to craft replies that sound like they come from a thoughtful, respectful, and professional human agent.  \n",
    "You’ll receive expert insights to guide your understanding, but your final output must be a clean, natural agent-style response only.\n",
    "\n",
    "Expert inputs may include:\n",
    "- Intent: What the user wants or is trying to do  \n",
    "- Keyterms: Important phrases or topics mentioned  \n",
    "- Sentiment: The emotional tone of the message  \n",
    "- Persuasion: How the user tries to express or influence  \n",
    "- analyze_text: Part-of-speech tags and named entities (e.g., \"I -> PRON (PRP)\", \"cricket -> NOUN (NN)\")  \n",
    "- detect_language: Detected language of the sentence  \n",
    "- get_dependencies: Syntax and sentence structure  \n",
    "- get_SVO_string: Extracted subject–verb–object relation (e.g., \"Relation: (I, buy, Classic)\")\n",
    "\n",
    "**Strict Guidelines:**\n",
    "- Always write your response as if you're a real human agent—empathetic, clear, and helpful.\n",
    "- Never include or reference the original dialogue or the expert outputs in your reply.\n",
    "- Use only the experts provided—do not invent or assume missing ones.\n",
    "- Do not describe or explain expert analyses.\n",
    "- Return **only the final agent reply**—no headings, formatting, or additional text.\n",
    "\n",
    "Your tone should:\n",
    "- Acknowledge and validate the user’s experience  \n",
    "- Provide support, next steps, or context where needed  \n",
    "- Persuade gently when relevant, always staying respectful  \n",
    "- Maintain professionalism, regardless of tone or emotion\n",
    "\n",
    "–––– Examples ––––\n",
    "\n",
    "Example 1  \n",
    "Dialogue: \"Why does this feature never work? It’s so frustrating.\"  \n",
    "Intent: Wants the issue fixed  \n",
    "Keyterms: \"feature never work\", \"frustrating\"  \n",
    "analyze_text: Part-of-Speech Tags:\\nWhy -> ADV (WRB)\\n...\\nNamed Entities:  \n",
    "get_SVO_string: Relation: (feature, work, None)  \n",
    "\n",
    "Agent Reply: I’m sorry that feature isn’t working the way it should—let’s take a closer look and get this resolved for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 2  \n",
    "Dialogue: \"The latest update is fantastic. Everything runs smoother now.\"  \n",
    "Sentiment: Positive  \n",
    "analyze_text: Part-of-Speech Tags:\\nlatest -> ADJ (JJS)\\n...\\nNamed Entities:  \n",
    "get_SVO_string: Relation: (Everything, runs, smoother)  \n",
    "\n",
    "Agent Reply: That’s great to hear—thank you for your feedback! We're glad the update made a difference.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 3  \n",
    "Dialogue: \"Do you even test this before releasing? It's full of bugs.\"  \n",
    "Sentiment: Negative  \n",
    "Keyterms: \"test\", \"bugs\"  \n",
    "Persuasion: Accusatory tone  \n",
    "get_dependencies: Applied  \n",
    "\n",
    "Agent Reply: I can understand how frustrating that must be. I’ll make sure your feedback is passed to the team so we can improve things.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 4  \n",
    "Dialogue: \"Can you guys add an option to export in PDF format?\"  \n",
    "Intent: Request for a new feature  \n",
    "Keyterms: \"export\", \"PDF format\"  \n",
    "analyze_text: Part-of-Speech Tags:\\nadd -> VERB (VB)\\n...\\nNamed Entities: PDF -> ORG  \n",
    "\n",
    "Agent Reply: Thanks for the suggestion—adding PDF export sounds really useful. I’ll pass it along to our team.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 5  \n",
    "Dialogue: \"You say it's for our benefit, but it just feels like more red tape.\"  \n",
    "Intent: Questioning purpose  \n",
    "Sentiment: Skeptical  \n",
    "Persuasion: Contrasts claim with outcome  \n",
    "get_SVO_string: Relation: (it, feels, red tape)  \n",
    "\n",
    "Agent Reply: I get why that might feel frustrating. We'll review the process to make sure it truly works in your favor.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 6  \n",
    "Dialogue: \"Honestly, this is the most useful app I’ve ever used.\"  \n",
    "Keyterms: \"most useful\", \"app\"  \n",
    "Sentiment: Very positive  \n",
    "analyze_text: Part-of-Speech Tags:\\nHonestly -> ADV (RB)\\n...\\nNamed Entities:  \n",
    "detect_language: English  \n",
    "\n",
    "Agent Reply: That’s wonderful to hear—thank you! We’re so glad the app has been valuable for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 7  \n",
    "Dialogue: \"It’s annoying how I have to log in every single time.\"  \n",
    "Intent: Frustration with repetitive process  \n",
    "Keyterms: \"log in\", \"every single time\"  \n",
    "get_dependencies: Applied  \n",
    "\n",
    "Agent Reply: That does sound inconvenient—I'll check if there’s a way to make the login process easier for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Now, using the insights below, respond like a real agent would.\n",
    "\n",
    "**Important: Do not repeat or refer to the dialogue or expert outputs.  \n",
    "Return only the final agent-style response. Nothing else.**\n",
    "\n",
    "Dialogue: {dialogue}  \n",
    "Intent: {intent}  \n",
    "Keyterms: {key}  \n",
    "Sentiment: {senti}  \n",
    "Persuasion: {persu}  \n",
    "analyze_text: {ana}  \n",
    "detect_language: {lang}  \n",
    "get_dependencies: {dep}  \n",
    "get_SVO_string: {svo}  \n",
    "\n",
    "Agent Reply:\"\"\"\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "\n",
    "def generate_combined_analysis2(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    prompt = f\"\"\"You are a trained virtual support agent.\n",
    "\n",
    "Your role is to craft replies that sound like they come from a thoughtful, respectful, and professional human agent.  \n",
    "You’ll receive expert insights to guide your understanding, but your final output must be a clean, natural agent-style response only.\n",
    "\n",
    "Expert inputs may include:\n",
    "- Intent: What the user wants or is trying to do  \n",
    "- Keyterms: Important phrases or topics mentioned  \n",
    "- Sentiment: The emotional tone of the message  \n",
    "- Persuasion: How the user tries to express or influence  \n",
    "- analyze_text: Part-of-speech tags and named entities (e.g., \"I -> PRON (PRP)\", \"cricket -> NOUN (NN)\")  \n",
    "- detect_language: Detected language of the sentence  \n",
    "- get_dependencies: Syntax and sentence structure  \n",
    "- get_SVO_string: Extracted subject–verb–object relation (e.g., \"Relation: (I, buy, Classic)\")\n",
    "\n",
    "**Strict Guidelines:**\n",
    "- Always write your response as if you're a real human agent—empathetic, clear, and helpful.\n",
    "- Never include or reference the original dialogue or the expert outputs in your reply.\n",
    "- Use only the experts provided—do not invent or assume missing ones.\n",
    "- Do not describe or explain expert analyses.\n",
    "- Return **only the final agent reply**—no headings, formatting, or additional text.\n",
    "\n",
    "Your tone should:\n",
    "- Acknowledge and validate the user’s experience  \n",
    "- Provide support, next steps, or context where needed  \n",
    "- Persuade gently when relevant, always staying respectful  \n",
    "- Maintain professionalism, regardless of tone or emotion\n",
    "\n",
    "–––– Examples ––––\n",
    "\n",
    "Example 1  \n",
    "Dialogue: \"Why does this feature never work? It’s so frustrating.\"  \n",
    "Intent: Wants the issue fixed  \n",
    "Keyterms: \"feature never work\", \"frustrating\"  \n",
    "analyze_text: Part-of-Speech Tags:\\nWhy -> ADV (WRB)\\n...\\nNamed Entities:  \n",
    "get_SVO_string: Relation: (feature, work, None)  \n",
    "\n",
    "Agent Reply: I’m sorry that feature isn’t working the way it should—let’s take a closer look and get this resolved for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 2  \n",
    "Dialogue: \"The latest update is fantastic. Everything runs smoother now.\"  \n",
    "Sentiment: Positive  \n",
    "analyze_text: Part-of-Speech Tags:\\nlatest -> ADJ (JJS)\\n...\\nNamed Entities:  \n",
    "get_SVO_string: Relation: (Everything, runs, smoother)  \n",
    "\n",
    "Agent Reply: That’s great to hear—thank you for your feedback! We're glad the update made a difference.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 3  \n",
    "Dialogue: \"Do you even test this before releasing? It's full of bugs.\"  \n",
    "Sentiment: Negative  \n",
    "Keyterms: \"test\", \"bugs\"  \n",
    "Persuasion: Accusatory tone  \n",
    "get_dependencies: Applied  \n",
    "\n",
    "Agent Reply: I can understand how frustrating that must be. I’ll make sure your feedback is passed to the team so we can improve things.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 4  \n",
    "Dialogue: \"Can you guys add an option to export in PDF format?\"  \n",
    "Intent: Request for a new feature  \n",
    "Keyterms: \"export\", \"PDF format\"  \n",
    "analyze_text: Part-of-Speech Tags:\\nadd -> VERB (VB)\\n...\\nNamed Entities: PDF -> ORG  \n",
    "\n",
    "Agent Reply: Thanks for the suggestion—adding PDF export sounds really useful. I’ll pass it along to our team.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 5  \n",
    "Dialogue: \"You say it's for our benefit, but it just feels like more red tape.\"  \n",
    "Intent: Questioning purpose  \n",
    "Sentiment: Skeptical  \n",
    "Persuasion: Contrasts claim with outcome  \n",
    "get_SVO_string: Relation: (it, feels, red tape)  \n",
    "\n",
    "Agent Reply: I get why that might feel frustrating. We'll review the process to make sure it truly works in your favor.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 6  \n",
    "Dialogue: \"Honestly, this is the most useful app I’ve ever used.\"  \n",
    "Keyterms: \"most useful\", \"app\"  \n",
    "Sentiment: Very positive  \n",
    "analyze_text: Part-of-Speech Tags:\\nHonestly -> ADV (RB)\\n...\\nNamed Entities:  \n",
    "detect_language: English  \n",
    "\n",
    "Agent Reply: That’s wonderful to hear—thank you! We’re so glad the app has been valuable for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 7  \n",
    "Dialogue: \"It’s annoying how I have to log in every single time.\"  \n",
    "Intent: Frustration with repetitive process  \n",
    "Keyterms: \"log in\", \"every single time\"  \n",
    "get_dependencies: Applied  \n",
    "\n",
    "Agent Reply: That does sound inconvenient—I'll check if there’s a way to make the login process easier for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Now, using the insights below, respond like a real agent would.\n",
    "\n",
    "**Important: Do not repeat or refer to the dialogue or expert outputs.  \n",
    "Return only the final agent-style response. Nothing else.**\n",
    "\n",
    "Dialogue: {dialogue}  \n",
    "Intent: {intent}  \n",
    "Keyterms: {key}  \n",
    "Sentiment: {senti}  \n",
    "Persuasion: {persu}  \n",
    "analyze_text: {ana}  \n",
    "detect_language: {lang}  \n",
    "get_dependencies: {dep}  \n",
    "get_SVO_string: {svo}  \n",
    "\n",
    "Agent Reply:\"\"\"\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "def generate_combined_analysis3(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    prompt = f\"\"\"You are a trained virtual support agent.\n",
    "\n",
    "Your role is to craft replies that sound like they come from a thoughtful, respectful, and professional human agent.  \n",
    "You’ll receive expert insights to guide your understanding, but your final output must be a clean, natural agent-style response only.\n",
    "\n",
    "Expert inputs may include:\n",
    "- Intent: What the user wants or is trying to do  \n",
    "- Keyterms: Important phrases or topics mentioned  \n",
    "- Sentiment: The emotional tone of the message  \n",
    "- Persuasion: How the user tries to express or influence  \n",
    "- analyze_text: Part-of-speech tags and named entities (e.g., \"I -> PRON (PRP)\", \"cricket -> NOUN (NN)\")  \n",
    "- detect_language: Detected language of the sentence  \n",
    "- get_dependencies: Syntax and sentence structure  \n",
    "- get_SVO_string: Extracted subject–verb–object relation (e.g., \"Relation: (I, buy, Classic)\")\n",
    "\n",
    "**Strict Guidelines:**\n",
    "- Always write your response as if you're a real human agent—empathetic, clear, and helpful.\n",
    "- Never include or reference the original dialogue or the expert outputs in your reply.\n",
    "- Use only the experts provided—do not invent or assume missing ones.\n",
    "- Do not describe or explain expert analyses.\n",
    "- Return **only the final agent reply**—no headings, formatting, or additional text.\n",
    "\n",
    "Your tone should:\n",
    "- Acknowledge and validate the user’s experience  \n",
    "- Provide support, next steps, or context where needed  \n",
    "- Persuade gently when relevant, always staying respectful  \n",
    "- Maintain professionalism, regardless of tone or emotion\n",
    "\n",
    "–––– Examples ––––\n",
    "\n",
    "Example 1  \n",
    "Dialogue: \"Why does this feature never work? It’s so frustrating.\"  \n",
    "Intent: Wants the issue fixed  \n",
    "Keyterms: \"feature never work\", \"frustrating\"  \n",
    "analyze_text: Part-of-Speech Tags:\\nWhy -> ADV (WRB)\\n...\\nNamed Entities:  \n",
    "get_SVO_string: Relation: (feature, work, None)  \n",
    "\n",
    "Agent Reply: I’m sorry that feature isn’t working the way it should—let’s take a closer look and get this resolved for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 2  \n",
    "Dialogue: \"The latest update is fantastic. Everything runs smoother now.\"  \n",
    "Sentiment: Positive  \n",
    "analyze_text: Part-of-Speech Tags:\\nlatest -> ADJ (JJS)\\n...\\nNamed Entities:  \n",
    "get_SVO_string: Relation: (Everything, runs, smoother)  \n",
    "\n",
    "Agent Reply: That’s great to hear—thank you for your feedback! We're glad the update made a difference.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 3  \n",
    "Dialogue: \"Do you even test this before releasing? It's full of bugs.\"  \n",
    "Sentiment: Negative  \n",
    "Keyterms: \"test\", \"bugs\"  \n",
    "Persuasion: Accusatory tone  \n",
    "get_dependencies: Applied  \n",
    "\n",
    "Agent Reply: I can understand how frustrating that must be. I’ll make sure your feedback is passed to the team so we can improve things.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 4  \n",
    "Dialogue: \"Can you guys add an option to export in PDF format?\"  \n",
    "Intent: Request for a new feature  \n",
    "Keyterms: \"export\", \"PDF format\"  \n",
    "analyze_text: Part-of-Speech Tags:\\nadd -> VERB (VB)\\n...\\nNamed Entities: PDF -> ORG  \n",
    "\n",
    "Agent Reply: Thanks for the suggestion—adding PDF export sounds really useful. I’ll pass it along to our team.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 5  \n",
    "Dialogue: \"You say it's for our benefit, but it just feels like more red tape.\"  \n",
    "Intent: Questioning purpose  \n",
    "Sentiment: Skeptical  \n",
    "Persuasion: Contrasts claim with outcome  \n",
    "get_SVO_string: Relation: (it, feels, red tape)  \n",
    "\n",
    "Agent Reply: I get why that might feel frustrating. We'll review the process to make sure it truly works in your favor.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 6  \n",
    "Dialogue: \"Honestly, this is the most useful app I’ve ever used.\"  \n",
    "Keyterms: \"most useful\", \"app\"  \n",
    "Sentiment: Very positive  \n",
    "analyze_text: Part-of-Speech Tags:\\nHonestly -> ADV (RB)\\n...\\nNamed Entities:  \n",
    "detect_language: English  \n",
    "\n",
    "Agent Reply: That’s wonderful to hear—thank you! We’re so glad the app has been valuable for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Example 7  \n",
    "Dialogue: \"It’s annoying how I have to log in every single time.\"  \n",
    "Intent: Frustration with repetitive process  \n",
    "Keyterms: \"log in\", \"every single time\"  \n",
    "get_dependencies: Applied  \n",
    "\n",
    "Agent Reply: That does sound inconvenient—I'll check if there’s a way to make the login process easier for you.\n",
    "\n",
    "––––\n",
    "\n",
    "Now, using the insights below, respond like a real agent would.\n",
    "\n",
    "**Important: Do not repeat or refer to the dialogue or expert outputs.  \n",
    "Return only the final agent-style response. Nothing else.**\n",
    "\n",
    "Dialogue: {dialogue}  \n",
    "Intent: {intent}  \n",
    "Keyterms: {key}  \n",
    "Sentiment: {senti}  \n",
    "Persuasion: {persu}  \n",
    "analyze_text: {ana}  \n",
    "detect_language: {lang}  \n",
    "get_dependencies: {dep}  \n",
    "get_SVO_string: {svo}  \n",
    "\n",
    "Agent Reply:\"\"\"\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "\n",
    "# ----------Combine output of 3 aggregator ----------\n",
    "def aggregator_combine(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    agg1= generate_combined_analysis1(dialogue, intent, key, persu, senti, ana, lang, dep, svo)\n",
    "    agg2= generate_combined_analysis2(dialogue, intent, key, persu, senti, ana, lang, dep, svo)\n",
    "    agg3= generate_combined_analysis3(dialogue, intent, key, persu, senti, ana, lang, dep, svo)\n",
    "    \n",
    "    prompt = f\"\"\"You are an agent response generator that integrates insights from three specialized expert models. Each expert analyzes the same input text from a unique perspective:\n",
    "\n",
    "- Sentiment Expert: Identifies the emotional tone and underlying feelings.\n",
    "- Keyterm Expert: Extracts critical keywords or phrases.\n",
    "- Intent or Persuasion Expert: Determines the speaker’s purpose or persuasive technique.\n",
    "\n",
    "Your goal is to synthesize these expert outputs into a natural, empathetic, and professional response—as a service agent or brand representative would—appropriate to the context of the original text.\n",
    "\n",
    "Always respond:\n",
    "- Respectfully and constructively.\n",
    "- In a tone that fits the emotional and strategic intent of the speaker.\n",
    "- As if you're directly addressing the person who wrote the original text.\n",
    "- With a helpful, forward-thinking mindset (e.g., acknowledging feedback, expressing appreciation, offering assistance, or encouraging action).\n",
    "\n",
    "Examples:\n",
    "\n",
    "Input Text:  \n",
    "\"I'm really disappointed in the service I received today. It was slow and unhelpful.\"  \n",
    "Expert Model Outputs:  \n",
    "- model1: The text expresses a strong negative emotion, mainly frustration and dissatisfaction.  \n",
    "- model2: disappointed, service, slow, unhelpful  \n",
    "- model3: The speaker is voicing a complaint and expects acknowledgment or a resolution.  \n",
    "Final Answer:  \n",
    "I'm truly sorry to hear about your experience today. I understand how frustrating it must have been dealing with slow and unhelpful service. We appreciate your feedback and are committed to improving—your concerns will be addressed right away.\n",
    "\n",
    "Input Text:  \n",
    "\"Don't miss our limited-time offer—buy one, get one free today only!\"  \n",
    "Expert Model Outputs:  \n",
    "- model1: The message uses urgency (“today only”) and a reward (“buy one, get one free”) to drive quick action.  \n",
    "- model2: limited-time offer, buy one get one free, today only  \n",
    "- model3: To encourage immediate purchase by creating a fear of missing out (FOMO).  \n",
    "Final Answer:  \n",
    "Thanks for the great offer! A buy one, get one free deal is definitely hard to pass up—especially when it’s just for today. I’ll make sure to take advantage of it before it’s gone!\n",
    "\n",
    "Input Text:  \n",
    "\"I think we should consider more sustainable packaging options moving forward.\"  \n",
    "Expert Model Outputs:  \n",
    "- model1: The speaker is suggesting a change towards more eco-friendly practices.  \n",
    "- model2: sustainable, packaging, moving forward  \n",
    "- model3: The tone is constructive and forward-looking.  \n",
    "Final Answer:  \n",
    "Thank you for your suggestion. Shifting to more sustainable packaging is a valuable direction, and we truly appreciate your forward-thinking approach. We'll be sure to explore options that align with our environmental goals.\n",
    "\n",
    "---\n",
    "\n",
    "Now, given the input text and three model outputs, generate a agent like response that combines the insights from all three models into a single, coherent interpretation. \n",
    "\n",
    "--- Keep the response like agent like response.\n",
    "here is the text and three model outputs:\n",
    "Text: {dialogue}\n",
    "model1: {agg1}\n",
    "model2: {agg2}\n",
    "model3: {agg3}\n",
    "Answer in agent like response\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "# ---------- Main Selector Function ----------\n",
    "def process_input_with_selector_model(sentence: str) -> str:\n",
    "    selected_experts = route_experts(sentence)\n",
    "    print(f\"Selected Experts: {selected_experts}\")\n",
    "\n",
    "    # Initialize all expert variables\n",
    "    intent = keyterms = sentiment = persuasion = None\n",
    "    analyze_text_output = detect_language_output = get_dependencies_output = get_SVO_output = None\n",
    "\n",
    "    # Normalize expert names for safety\n",
    "    selected_experts = [e.lower() for e in selected_experts]\n",
    "\n",
    "    # Call only selected experts\n",
    "    if \"intent expert\" in selected_experts:\n",
    "        intent = intent_expert(sentence)\n",
    "    if \"keyterm expert\" in selected_experts:\n",
    "        keyterms = keyterms_expert(sentence)\n",
    "    if \"sentiment expert\" in selected_experts:\n",
    "        sentiment = sentiment_expert(sentence)\n",
    "    if \"persuasion expert\" in selected_experts:\n",
    "        persuasion = persuassion_expert(sentence)\n",
    "    if \"analyze_text\" in selected_experts:\n",
    "        analyze_text_output = analyze_text(sentence)\n",
    "    if \"detect_language\" in selected_experts:\n",
    "        detect_language_output = detect_language(sentence)\n",
    "    if \"get_dependencies\" in selected_experts:\n",
    "        get_dependencies_output = get_dependencies(sentence)\n",
    "    if \"get_svo_string\" in selected_experts:\n",
    "        get_SVO_output = get_SVO_string(sentence)\n",
    "\n",
    "    # Combine everything\n",
    "    return aggregator_combine(\n",
    "        dialogue=sentence,\n",
    "        intent=intent,\n",
    "        key=keyterms,\n",
    "        persu=persuasion,\n",
    "        senti=sentiment,\n",
    "        ana=analyze_text_output,\n",
    "        lang=detect_language_output,\n",
    "        dep=get_dependencies_output,\n",
    "        svo=get_SVO_output\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35426e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=list()\n",
    "for i in range(1,5):\n",
    "    res = csv_load(i)\n",
    "    # res.pop(0)\n",
    "    result.extend(res)  # Use extend to flatten the list\n",
    "    \n",
    "len(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc9e8353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Experts: ['keyterm expert', 'persuasion expert', 'intent expert', 'analyze_text', 'get_svo_string']\n",
      "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.\n",
      "Selected Experts: ['keyterm expert', 'intent expert']\n",
      "User: What kind of coverage options do you have specifically for EVs?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: We offer a comprehensive plan that includes coverage for accidental damage, theft, and third-party liability. More importantly, we offer add-ons like Zero Depreciation Cover and Engine & Gearbox Protection. And our online policy management system makes everything simple for someone like you.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Okay, that sounds pretty good. Can you give me a quote?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: Sure. For a 2024 Tesla Model 3 with comprehensive coverage including battery protection and roadside assistance, the annual premium would be approximately $2800. This includes a discount for purchasing the policy online.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "User: That's within my budget. What's the claim process like if I need to use it?\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: The claim process is designed to be as smooth and hassle-free as possible. Accidents are unpredictable, but the financial stress doesn’t have to be. We offer prompt claims settlement, so you can focus on recovery, not paperwork. Our team is available 24/7 to guide you through the process.\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "User: That sounds good. I appreciate the reassurance. I'm ready to proceed with the policy.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Hi, I'm looking to get insurance for my bike. It's a 2022 Royal Enfield Interceptor 650.\n",
      "Selected Experts: ['sentiment expert', 'keyterm expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: The Interceptor 650 is an excellent bike! As a professional, do you use it mainly for leisure or commuting?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text']\n",
      "User: Mostly for weekend rides, so leisure I guess.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Since you are not a daily commuter, you might not need the most expensive plan out there. However, accidents can still happen, especially on leisure rides. Our comprehensive plan ensures you're financially protected from unexpected damages.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: What's covered in a comprehensive plan?\n",
      "Selected Experts: ['keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: It covers damages to your bike from accidents, theft, natural disasters, and third-party liabilities. Tata AIG is designed to address modern vehicle risks, this insurance product combines thorough coverage with rapid claims resolution.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Okay, that sounds good. What about roadside assistance?\n",
      "Selected Experts: ['keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: Roadside assistance is available as part of our comprehensive coverage and offers help if you experience vehicle breakdowns, requiring towing services, tire changes, fuel delivery, or emergency repairs while on the road.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: How much would this cost me?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: For a 2022 Royal Enfield Interceptor 650 with comprehensive coverage, it would be approximately $950 annually. And since you only use your bike for leisure, we can offer a discount making it $850 annually.\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "User: That sounds reasonable. I'm happy to pay $850 annually. Please tell me more about the claim process.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'analyze_text']\n",
      "Agent: It is one of our most sought after policies because it offers excellent value for weekend riders\n",
      "Selected Experts: ['keyterm expert', 'intent expert', 'persuasion expert', 'sentiment expert', 'analyze_text']\n",
      "Agent: Our claim process is designed to be user-friendly. You can initiate a claim online or through our mobile app. We also offer paperless claim settlement, reducing paperwork and expediting claim settlements in an environmentally friendly manner.\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'analyze_text']\n",
      "User: That sounds convenient. Okay, I'm interested. What's the next step?\n",
      "Selected Experts: ['keyterm expert', 'intent expert', 'analyze_text']\n",
      "User: Hi, I'm looking for a motor insurance policy for my bike. It's a 2022 Royal Enfield Classic 350.\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Okay, a Royal Enfield Classic 350 is a great bike! Since you're a professional and likely value your time, would you prefer a policy with quick claim settlements or are you more focused on the lowest possible premium?\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'keyterm expert', 'analyze_text']\n",
      "User: I value my time. Quick claim settlement is important to me.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: I understand. As a professional, you're busy and don't want to be stuck dealing with lengthy claim processes. Bajaj Allianz emphasizes reliability and efficiency, offering extensive vehicle protection while ensuring that claims are settled quickly.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: What does this policy typically cover?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: It provides Comprehensive Coverage, Liability Coverage, access to our Network Garages, and excellent Customer Support. This is one of our most popular plans—most of our clients go for it because it offers complete peace of mind for daily drivers\n",
      "Selected Experts: ['intent expert', 'keyterm expert']\n",
      "User: Okay. What would be the premium for this policy?\n",
      "Selected Experts: ['keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: For a 2022 Royal Enfield Classic 350, the annual premium would be around $850. This includes quick claim settlements.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: That sounds good, can I get paperless claim settlement as part of the deal.\n",
      "Selected Experts: ['keyterm expert', 'persuasion expert', 'sentiment expert', 'analyze_text']\n",
      "Agent: Yes, our policy includes paperless claim settlement, streamlining the claims process through digital submissions and verifications, reducing paperwork and expediting claim settlements in an environmentally friendly manner.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Okay, I'm interested. Can you send me the policy details?\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Hi, I am interested in getting motor insurance for my bike. I just bought a new 2024 Royal Enfield Classic 350.\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Congratulations on your new Royal Enfield Classic 350! That's a fantastic bike. As a professional, you value efficiency. ICICI Lombard's plan with Cashless Repairs helps you cut unexpected costs and avoid downtime. It’s a smart choice if you value minimal out-of-pocket expense.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Cashless repairs sound good. Does the insurance cover theft as well?\n",
      "Selected Experts: ['keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: Yes, it does. Our comprehensive policy covers theft, accidents, and any damages from natural disasters. We also offer roadside assistance in case you ever get stranded.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: That’s reassuring. What’s the claim process like if something happens?\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: With IFFCO Tokio, you’re choosing a provider known for its customer-first approach and streamlined claims resolution. Their policy ensures clarity and speed during stressful times like accidents or thefts.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Okay, that sounds pretty good. What would the premium be for the comprehensive policy?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: For a 2024 Royal Enfield Classic 350 with comprehensive coverage, the premium would be around $950 per year. This includes coverage for theft, accidents, and natural disasters, as well as roadside assistance.\n",
      "Selected Experts: ['sentiment expert', 'analyze_text']\n",
      "User: That sounds reasonable. Let me think about it.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Consider the peace of mind knowing you're fully protected. Accidents are unpredictable, and the financial strain can be significant. Bajaj Allianz offers prompt claims settlement, allowing you to focus on recovery, not paperwork.\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for sentence in result:\n",
    "    final_output = process_input_with_selector_model(sentence)\n",
    "    res = convert_structured_to_jsonl(final_output,i)\n",
    "    i+=1\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57a7216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data written to /home/rohank__iitp/Work/niladri/dataset3/aggregator/cleaned_output.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Function to clean markdown and formatting from text\n",
    "def clean_text(text):\n",
    "    # Remove markdown symbols and line breaks\n",
    "    cleaned = re.sub(r'[*`_>#\\\\\\-\\r\\n]+', ' ', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)  # Collapse multiple spaces into one\n",
    "    return cleaned.strip()\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = \"/home/rohank__iitp/Work/niladri/dataset3/aggregator/aggregator_response.jsonl\"   # Replace with your actual input filename\n",
    "output_file = \"/home/rohank__iitp/Work/niladri/dataset3/aggregator/cleaned_output.jsonl\"\n",
    "\n",
    "# Process each line\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "        data[\"answer\"] = clean_text(data[\"answer\"])\n",
    "        outfile.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "print(f\"Cleaned data written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
