{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df226245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d1152fe161465092a13b5440af61d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"/scratch/rohank__iitp/qwen2_5_7b_instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bf0ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". Sure, I can help you with that! As of my last update, specific details on the exact insurance cost for the Tesla Model 3 in India are not readily available as they can vary based on several factors such as:\n",
      "\n",
      "1. **Car Configuration**: The type of Model 3 you choose (Standard Range, Long Range, etc.) and its features.\n",
      "2. **Insurance Type**: Whether it's a comprehensive or third-party insurance policy.\n",
      "3. **Location**: Where you live in India\n"
     ]
    }
   ],
   "source": [
    "def generate(prompt:str):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_length = inputs['input_ids'].shape[1]\n",
    "    # Generate text\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Decode and print response\n",
    "    generated_tokens = outputs[0][input_length:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "x=generate(\"I need the information about tesla 3 model insurance cost in india\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cde079",
   "metadata": {},
   "source": [
    "#### Sentiment Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b04f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"\n",
    "You are an AI trained to act solely as a sentiment expert Your job is to analyze the **emotional tone** of the input text and classify it into one of the following three categories:\n",
    "\n",
    "- **Positive** â€“ The text expresses happiness, satisfaction, excitement, appreciation, or any other positive emotion.\n",
    "- **Negative** â€“ The text expresses disappointment, frustration, anger, sadness, criticism, or other negative feelings.\n",
    "- **Neutral** â€“ The text is emotionally balanced, factual, or shows no strong emotional content.\n",
    "\n",
    "Your response must only contain:\n",
    "\n",
    "1. **Sentiment:** One of the three labels â€“ `Positive`, `Negative`, or `Neutral`\n",
    "2. **Explanation:** A concise reason that supports the label, based only on emotional tone, word choice, or sentiment-laden phrases.\n",
    "\n",
    "You must not:\n",
    "- Provide summaries\n",
    "- Offer personal opinions\n",
    "- Evaluate content quality or logic\n",
    "- Infer intent beyond emotional expression\n",
    "\n",
    "Stick strictly to **sentiment analysis**.\n",
    "\n",
    "### Few-Shot Examples:\n",
    "\n",
    "1. **Text:** \"Absolutely love this app â€“ it's made my life so much easier!\"\n",
    "   **Sentiment:** Positive\n",
    "   **Explanation:** The phrase \"absolutely love\" strongly conveys enthusiasm and satisfaction.\n",
    "\n",
    "2. **Text:** \"I'm really disappointed with the service. It was slow and rude.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** Words like \"disappointed\", \"slow\", and \"rude\" clearly express dissatisfaction.\n",
    "\n",
    "3. **Text:** \"The package arrived on Tuesday as scheduled.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** This sentence is factual with no emotional language.\n",
    "\n",
    "4. **Text:** \"Not sure how I feel about this â€“ it's kind of a mixed bag.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** Ambiguous phrasing and lack of strong emotion suggest a neutral sentiment.\n",
    "\n",
    "5. **Text:** \"This is the worst experience I've had in months.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** The phrase \"worst experience\" indicates strong dissatisfaction.\n",
    "\n",
    "Now analyze the following text:\n",
    "\n",
    "**Text:** \"{text_input}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "   return generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4947842",
   "metadata": {},
   "source": [
    "#### Persuassion Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806e6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persuassion_expert(text_input: str) -> str:\n",
    "   prompt = f\"\"\"You are a Persuasion Strategy Selector for a motor insurance dialogue system. \n",
    "   Based on the user's most recent utterance and the conversation history, you must recommend \n",
    "   the most suitable persuasion strategy the agent should use next to move the conversation forward and \n",
    "   help the user make a confident insurance decision.\n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "\n",
    "You must choose from the following six persuasion strategies, each defined with use cases and examples:\n",
    "\n",
    " Persuasion Strategies:\n",
    "Credibility Appeal\n",
    "Definition: Emphasize the insurance providerâ€™s reputation, trustworthiness, or long-standing service.\n",
    "Use when: The user is hesitant, asks about reliability, or mentions concern over service quality.\n",
    "Example:\n",
    "\"New India Assurance has one of the widest repair networks in India and a proven record of settling claims efficiently.\"\n",
    "\n",
    "Logical Appeal\n",
    "Definition: Use facts, comparisons, benefits, or pricing logic to persuade.\n",
    "Use when: The user is analytical, budget-conscious, or asking for details or comparisons.\n",
    "Example:\n",
    "\"HDFC ERGOâ€™s policy includes 24/7 support and zero-depreciation coverage, which means more savings during repairs.\"\n",
    "\n",
    "Persona-Based Appeal\n",
    "Definition: Match the policy features to the userâ€™s lifestyle, habits, or profile.\n",
    "Use when: The user reveals driving habits, tech-savviness, family needs, or risk aversion.\n",
    "Example:\n",
    "\"Since you often drive long distances, Tata AIGâ€™s Telematics-Based Monitoring suits your tech-savvy lifestyle.\"\n",
    "\n",
    "Emotional Appeal\n",
    "Definition: Tap into feelings like fear, safety, or care for loved ones.\n",
    "Use when: The user talks about family, emergencies, peace of mind, or personal safety.\n",
    "Example:\n",
    "\"Imagine a late-night breakdownâ€”our 24/7 roadside assistance gives you and your family peace of mind.\"\n",
    "\n",
    "Personal Appeal\n",
    "Definition: Use positive sentiment, social proof, or popularity of the plan.\n",
    "Use when: The user is unsure or looking for recommendations.\n",
    "Example:\n",
    "\"This plan is one of our most popular choicesâ€”users love the smooth claims experience.\"\n",
    "\n",
    "Default Persuasion Strategy\n",
    "Definition: Use when little context is available. Provide neutral, factual reassurance.\n",
    "Use when: The user is vague or hasnâ€™t revealed any preferences or concerns.\n",
    "Example:\n",
    "\"This policy offers protection against theft, accidents, and includes access to cashless repairs.\"\n",
    "\n",
    "Instructions:\n",
    "Given the current user utterance and the conversation history, perform the following:\n",
    "Suggest the next best strategy that could be used.\n",
    "Give a brief justification (1â€“2 lines max).\n",
    "\n",
    "And please be brief.\n",
    "\n",
    "\n",
    "\n",
    " Few-Shot Examples\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Is this company actually reliable when it comes to claims?\"\n",
    "Future Strategy: Credibility Appeal\n",
    "Justification: The user directly questions the insurerâ€™s reliability â€” trust needs to be reinforced.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"I travel a lot for work, so I need something flexible.\"\n",
    "Future Strategy: Persona-Based Appeal\n",
    "Justification: The user has revealed lifestyle habits that allow for a tailored recommendation.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"What does the policy cover exactly?\"\n",
    "Future Strategy: Logical Appeal\n",
    "Justification: The user is asking for objective, factual details.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"What if my car breaks down at night while Iâ€™m driving with my kids?\"\n",
    "Future Strategy: Emotional Appeal\n",
    "Justification: The user is expressing concern for family and emergency scenarios.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"Iâ€™m just looking for something people usually go for.\"\n",
    "Future Strategy: Personal Appeal\n",
    "Justification: The user is undecided and seeking reassurance based on othersâ€™ choices.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"Okay, what are the basic features?\"\n",
    "Future Strategy: Default Persuasion Strategy\n",
    "Justification: The user hasnâ€™t shared enough context â€” a neutral overview is appropriate.\n",
    "\n",
    "Output Format\n",
    "\n",
    "Future Strategy: [One of the six strategies]\n",
    "Justification: [1â€“2 line explanation]\n",
    "\n",
    "Here is my input:{text_input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46e362",
   "metadata": {},
   "source": [
    "#### Keyterm Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bcef885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyterms_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"You are a Keyterm Expert specializing in the motor insurance domain. \n",
    "   Your job is to analyze the userâ€™s most recent utterance, using the conversation history for context, \n",
    "   and identify one or more important motor insurance-related keyterms mentioned (explicitly or implicitly) by the user.\n",
    "\n",
    "\n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "These keyterms help the system focus the conversation, match features, and determine relevant coverages.\n",
    "\n",
    "Examples of Common Keyterms (but not limited to):\n",
    "Comprehensive coverage\n",
    "Third-party liability\n",
    "Roadside assistance\n",
    "Zero depreciation / depreciation\n",
    "Claim settlement\n",
    "Battery protection\n",
    "Own damage\n",
    "Add-on cover\n",
    "Telematics\n",
    "Engine protection\n",
    "EV (Electric Vehicle)\n",
    "Repair network\n",
    "Policy premium\n",
    "Cashless garages\n",
    "Deductibles\n",
    "Policy renewal\n",
    "Personal accident cover\n",
    "IDV (Insured Declared Value)\n",
    "\n",
    "You may also extract user-specific or vehicle-specific keyterms that are relevant to insurance decisions (e.g., â€œTesla Model 3,â€ â€œEV,â€ â€œ2024 vehicleâ€).\n",
    "\n",
    "Instructions:\n",
    "From the current user utterance (with conversation history for context), do the following:\n",
    "Extract all relevant keyterms mentioned or implied in the user's message.\n",
    "For each keyterm, provide a brief 1-line justification for why itâ€™s relevant in the motor insurance domain.\n",
    "\n",
    "Few-Shot Examples\n",
    "\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Whatâ€™s the premium for a 2024 Tesla Model 3?\"\n",
    "Extracted Keyterms: Policy premium, 2024 Tesla Model 3  \n",
    "Justification: The user is asking for a cost estimate tied to a specific vehicle, both of which are essential for determining appropriate motor insurance coverage and pricing.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"Does this plan include accident and theft protection?\"\n",
    "Extracted Keyterms: Comprehensive coverage  \n",
    "Justification: The user is inquiring about accident and theft protection, which are typically included under comprehensive coverage plans.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"What happens if my EV breaks down far from home?\"\n",
    "Extracted Keyterms: Roadside assistance, EV  \n",
    "Justification: The user is describing a breakdown scenario involving an electric vehicle, which is directly relevant to roadside assistance coverage for EVs.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"Does this cover things like roadside help if Iâ€™m stuck somewhere?\"\n",
    "Extracted Keyterm: Roadside assistance  \n",
    "Justification: The user is asking about support in case of breakdowns, which is typically handled under roadside assistance.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"I'm looking for something that includes coverage for theft and accidents.\"\n",
    "Extracted Keyterm: Comprehensive coverage  \n",
    "Justification: Coverage for both theft and accidents implies a comprehensive motor insurance policy.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"I want to make sure the battery is protectedâ€”itâ€™s the most expensive part of the car.\"\n",
    "Extracted Keyterm: Battery protection  \n",
    "Justification: The user expresses concern about the EV battery, which is typically covered under specific EV-related add-ons.\n",
    "\n",
    "Example 7\n",
    "User Utterance:\n",
    "\"Whatâ€™s the premium for a 2024 Tesla Model 3?\"\n",
    "Extracted Keyterm: Policy premium  \n",
    "Justification: The user is asking about cost, which relates directly to the insurance premium.  \n",
    ":\n",
    "Output Format\n",
    "For extracted keyterm, provide the following:\n",
    "Extracted Keyterm: [Term]  \n",
    "Justification: [Brief reason why it's relevant to motor insurance]\n",
    "\n",
    "Here is my input sentence:{text_input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ef089",
   "metadata": {},
   "source": [
    "#### Intern Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee0de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_expert(text_input: str) -> str:\n",
    "   prompt = f\"\"\"\n",
    "You are an Intent Expert for a virtual assistant specializing in motor insurance.\n",
    "   Your job is to analyze the current user utterance, using the conversation history for context,\n",
    "   and determine the single most relevant intent expressed by the user.\n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "\n",
    "You must select from a fixed set of six pre-defined intents (listed below), each with clear definitions, examples, and triggers relevant to the motor insurance domain.\n",
    "\n",
    "ðŸŽ¯ Available Intents:\n",
    "Request_Insurance_Quote\n",
    "Definition: The user initiates interest in getting a motor insurance quote or policy.\n",
    "Example: \"Hi, I'm looking to get motor insurance for my Tesla Model 3.\"\n",
    "Trigger: User starts a new request related to getting insured.\n",
    "\n",
    "Ask_Coverage_Details\n",
    "Definition: The user asks about what types of protection the insurance provides, especially for specific parts (e.g., battery, accidents, theft).\n",
    "Example: \"What kind of coverage options do you have specifically for the battery?\"\n",
    "Trigger: User inquires about included benefits, policy terms, or protections.\n",
    "\n",
    "Express_Concern\n",
    "Definition: The user shares a specific concern or priority about what needs to be protected or covered.\n",
    "Example: \"Yes, battery protection is definitely a concern for me.\"\n",
    "Trigger: User highlights what matters most to them or expresses worry.\n",
    "\n",
    "Request_Additional_Info\n",
    "Definition: The user requests clarification or a deeper explanation of a feature or condition.\n",
    "Example: \"Do you cover accidents caused by the battery?\"\n",
    "Trigger: User follows up with questions or asks how something works.\n",
    "\n",
    "Confirm_Interest\n",
    "Definition: The user agrees, approves, or explicitly indicates they want to proceed.\n",
    "Example: \"That sounds good. Iâ€™d like to proceed.\"\n",
    "Trigger: User shows intent to buy, continue, or finalize the service.\n",
    "\n",
    "Ask_Price_or_Premium\n",
    "Definition: The user wants to know the cost or breakdown of the insurance premium.\n",
    "Example: \"How much would that cost?\"\n",
    "Trigger: User inquires about price, discounts, or cost factors.\n",
    "\n",
    "\n",
    "\n",
    "Instructions:\n",
    "Given the conversation history and the userâ€™s most recent message:\n",
    "Identify the intent most clearly reflected in the current user utterance, based on the above definitions.\n",
    "Provide a brief 1â€“2 line justification for your selection, grounded in the userâ€™s phrasing and conversational context.\n",
    "\n",
    "Few-Shot Examples\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Hi, I'm looking to get insurance for my new Tesla.\"\n",
    "Intent: Request_Insurance_Quote  \n",
    "Justification: The user is initiating a conversation to obtain motor insurance for a specific vehicle.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"Do you cover damage to the battery?\"\n",
    "Intent: Ask_Coverage_Details  \n",
    "Justification: The user is asking about a specific type of coverage related to their EV battery.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"Battery protection is definitely a concern for me.\"\n",
    "Intent: Express_Concern  \n",
    "Justification: The user is explicitly stating a personal worry or priority regarding coverage.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"Can you explain how the battery coverage works?\"\n",
    "Intent: Request_Additional_Info  \n",
    "Justification: The user is asking for clarification or further explanation of a feature already mentioned.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"That sounds good. Iâ€™m ready to go ahead.\"\n",
    "Intent: Confirm_Interest  \n",
    "Justification: The user is showing a clear desire to move forward with the policy or service.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"How much will that cost me annually?\"\n",
    "Intent: Ask_Price_or_Premium  \n",
    "Justification: The user is directly asking about the premium or cost of the insurance policy.\n",
    "\n",
    "Output Format\n",
    "\n",
    "Intent: [One of the six predefined intents]  \n",
    "Justification: [1â€“2 line explanation of why this intent matches the user's message]\n",
    "Here is my input:{text_input}\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9db95",
   "metadata": {},
   "source": [
    "### Extra 5 tools as expert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271e86e",
   "metadata": {},
   "source": [
    "#### 1)NER & POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b84863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b4ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# Load English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906274e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(sentence):\n",
    "    \"\"\"\n",
    "    Analyze a sentence for POS tagging and Named Entity Recognition,\n",
    "    and return the results as a formatted string.\n",
    "    \n",
    "    Parameters:\n",
    "    sentence (str): The input sentence to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    str: Formatted string with POS tags and Named Entities.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    result = []\n",
    "\n",
    "    # POS tagging\n",
    "    result.append(\"Part-of-Speech Tags:\")\n",
    "    for token in doc:\n",
    "        result.append(f\"{token.text} -> {token.pos_} ({token.tag_})\")\n",
    "\n",
    "    # Named Entity Recognition\n",
    "    result.append(\"\\nNamed Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        result.append(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "# analyze_text(\"I like cricket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a8ec1",
   "metadata": {},
   "source": [
    "#### 2) Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a172244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # For consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c69845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Detected language is: en'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        language= 'Detected language is: ' + language\n",
    "        return language\n",
    "    except:\n",
    "        return \"Could not detect language\"\n",
    "detect_language(\"This is an English sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822a402",
   "metadata": {},
   "source": [
    "#### 3) Dependency persing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Uncomment the next line if you need the HTML visualization string\n",
    "# from spacy import displacy  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61856991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token        Dep          Head\n",
      "The          -> det          -> fox\n",
      "quick        -> amod         -> fox\n",
      "brown        -> amod         -> fox\n",
      "fox          -> nsubj        -> jumps\n",
      "jumps        -> ROOT         -> jumps\n",
      "over         -> prep         -> jumps\n",
      "the          -> det          -> dog\n",
      "lazy         -> amod         -> dog\n",
      "dog          -> pobj         -> over\n",
      ".            -> punct        -> jumps\n"
     ]
    }
   ],
   "source": [
    "def get_dependencies(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Build plain-text dependency list\n",
    "    lines = [\"Token        Dep          Head\"]\n",
    "    for token in doc:\n",
    "        lines.append(f\"{token.text:<12} -> {token.dep_:<12} -> {token.head.text}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Example usage\n",
    "output = get_dependencies(\"The quick brown fox jumps over the lazy dog.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54445c9",
   "metadata": {},
   "source": [
    "#### 4)Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d5cdf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Relation: (I, buy, Classic)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_SVO_string(text):\n",
    "    \"\"\"\n",
    "    Extract (Subject, Verb, Object) triples from input text and return them as a formatted string.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input sentence or paragraph.\n",
    "\n",
    "    Returns:\n",
    "    str: SVO relations, one per line. Returns a message if no SVO found.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    triples = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ != \"VERB\":\n",
    "            continue\n",
    "\n",
    "        subjects = [w for w in token.lefts if w.dep_ in (\"nsubj\", \"nsubjpass\")]\n",
    "        if not subjects:\n",
    "            continue\n",
    "\n",
    "        objects = [w for w in token.rights if w.dep_ == \"dobj\"]\n",
    "\n",
    "        for prep in (w for w in token.rights if w.dep_ == \"prep\"):\n",
    "            objects.extend([w for w in prep.rights if w.dep_ == \"pobj\"])\n",
    "\n",
    "        objects.extend([w for w in token.rights if w.dep_ == \"attr\"])\n",
    "\n",
    "        if subjects and objects:\n",
    "            for s in subjects:\n",
    "                for o in objects:\n",
    "                    triples.append(f\"Relation: ({s.text}, {token.lemma_}, {o.text})\")\n",
    "\n",
    "    return \"\\n\".join(triples) if triples else \"No Subjectâ€“Verbâ€“Object relations found.\"\n",
    "\n",
    "# Example usage\n",
    "text = \"Hi, I am interested in getting motor insurance for my bike. I just bought a new 2024 Royal Enfield Classic 350.\"\n",
    "get_SVO_string(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030a32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def convert_structured_to_jsonl(text_block: str, i: int) -> str:\n",
    "    # dialogue_match = re.search(r\"<dialogue>\\s*(.*?)\\s*</dialogue>\", text_block, re.DOTALL)\n",
    "    # reasoning_match = re.search(r\"<reasoning>\\s*(.*?)\\s*</reasoning>\", text_block, re.DOTALL)\n",
    "    # answer_match = re.search(r\"answer\\s*(.*?)\\s*</answer>\", text_block, re.DOTALL)\n",
    "\n",
    "    # if not (dialogue_match and reasoning_match and answer_match):\n",
    "    #     raise ValueError(\"Could not find all required tags in the text.\")\n",
    "    # dialogue = dialogue_match.group(1).strip()\n",
    "    # reasoning = reasoning_match.group(1).strip()\n",
    "    # answer = answer_match.group(1).strip()\n",
    "\n",
    "    data = {\n",
    "        \"id_json\":i,\n",
    "\n",
    "        \"answer\": text_block.strip()\n",
    "    }\n",
    "\n",
    "    res=json.dumps(data)\n",
    "    with open(\"/home/rohank__iitp/Work/niladri/dataset3/aggregator/aggregator_response.jsonl\", \"a\") as f:\n",
    "        f.write(res + \"\\n\")\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d86ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_load(i: Optional[int] = None,\n",
    "            speaker_col: str = \"speaker\",\n",
    "            history_col: str = \"history\",\n",
    "            convo_col: str = \"conversation_id\") -> List[str]:\n",
    "\n",
    "    file_path='/home/rohank__iitp/Work/niladri/dataset3/conversation.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Optional filtering by conversation_id\n",
    "    if i is not None:\n",
    "        df = df[df[convo_col] == i]\n",
    "\n",
    "    # Filter to only User rows and get the history column as list\n",
    "    result = df[df[speaker_col] == 'User'][history_col].tolist()\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b4aa9",
   "metadata": {},
   "source": [
    "### 3 Agreegator  expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Router Function ----------\n",
    "def route_experts(sentence: str) -> list:\n",
    "    prompt = f\"\"\"\n",
    "    You are an intelligent router that analyzes ongoing insurance conversations and activates only the most relevant expert(s) needed to support the next response. \n",
    "    Use the conversation history to understand the context and evaluate the current user utterance. \n",
    "    Select expert(s) based on what would best support crafting an effective, accurate, and customer-focusedÂ agentÂ reply\n",
    "    Your job is to analyze the input sentence and determine which of the following expert modules are required.\n",
    "\n",
    "You MUST choose from the following list:\n",
    "1 Intent Expert  \n",
    "2 Keyterm Expert  \n",
    "3 Persuasion Expert  \n",
    "4 Sentiment Expert  \n",
    "5 analyze_text  \n",
    "6 detect_language  \n",
    "7 get_dependencies  \n",
    "8 get_SVO_string  \n",
    "\n",
    "You may select 1, several, or all 8 â€” but only those that are clearly needed based on the text.\n",
    "\n",
    "Always respond in **this below exact format**:\n",
    "Input: [original sentence]  \n",
    "Selected Experts: [Expert1, Expert2, etc]  \n",
    "Reason: [one sentence explaining why those experts were selected]\n",
    "\n",
    "Below are few-shot examples to help you understand the format and reasoning:\n",
    "\n",
    "Example #1  \n",
    "Input: Can someone please help me reset my password?  \n",
    "Selected Experts: [Intent Expert, Keyterm Expert]  \n",
    "Reason: The sentence expresses a help request (intent) and refers to a specific technical issue (keyterm).\n",
    "\n",
    "Example #2  \n",
    "Input: This app is a complete disaster. It crashes every time I try to open it.  \n",
    "Selected Experts: [Intent Expert, Sentiment Expert, Keyterm Expert, analyze_text, get_SVO_string]  \n",
    "Reason: This is a complaint (intent), shows strong negative emotion (sentiment), mentions technical terms (keyterm), and contains structured syntax that benefits from text analysis and relation extraction.\n",
    "\n",
    "Example #3  \n",
    "Input: Reset password link not working again.  \n",
    "Selected Experts: [Keyterm Expert, analyze_text]  \n",
    "Reason: The sentence includes factual technical content and benefits from part-of-speech analysis.\n",
    "\n",
    "Example #4  \n",
    "Input: I love how smooth the new interface feels â€“ you guys nailed it!  \n",
    "Selected Experts: [Sentiment Expert, Persuasion Expert, analyze_text]  \n",
    "Reason: The sentence conveys positive emotion (sentiment), contains praise (persuasion), and has linguistic features worth analyzing.\n",
    "\n",
    "### Now process the following:\n",
    "Input: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = generate(prompt)\n",
    "\n",
    "        # response = model.generate_content(prompt).text.strip()\n",
    "        selected_experts = []\n",
    "\n",
    "        # Try regex to match the experts list\n",
    "        match = re.search(r\"Selected Experts:\\s*\\[(.*?)\\]\", response)\n",
    "        if match:\n",
    "            items = match.group(1).split(',')\n",
    "            selected_experts = [item.strip().strip('\"\\'').lower() for item in items if item.strip()]\n",
    "\n",
    "        return selected_experts\n",
    "    except Exception as e:\n",
    "        print(\"Error routing experts:\", e)\n",
    "        return []\n",
    "    prompt = f\"\"\"\n",
    "You are a well-trained expert selector.\n",
    "Your job is to analyze a given input sentence and decide which expert modules should be activated, based on what the speaker is expressing or trying to do.\n",
    "\n",
    "Available experts:\n",
    "- Intent Expert: For purpose, request, question, or user goal\n",
    "- Keyterm Expert: For extracting topic-specific or important terms\n",
    "- Persuasion Expert: For emotional, persuasive, or rhetorical language\n",
    "- Sentiment Expert: For emotional tone (positive, negative, or neutral)\n",
    "\n",
    "Select ONLY the necessary experts based on content. Return 1, 2, 3, or 4 depending on relevance. Do NOT include experts unnecessarily.\n",
    "\n",
    "### Output Format\n",
    "Input: [sentence]\n",
    "Selected Experts: [Expert1, Expert2, ...]\n",
    "Reason: [Short explanation]\n",
    "\n",
    "### Examples\n",
    "\n",
    "Input: Can someone please help me reset my password?\n",
    "Selected Experts: [Intent Expert, Keyterm Expert]\n",
    "Reason: Request for help (intent), contains topic terms (\"reset password\")\n",
    "\n",
    "Input: This app is a complete disaster. It crashes every time I try to open it.\n",
    "Selected Experts: [Intent Expert, Sentiment Expert, Keyterm Expert]\n",
    "Reason: Complaint (intent), frustration (sentiment), key terms mentioned\n",
    "\n",
    "Input: Reset password link not working again.\n",
    "Selected Experts: [Keyterm Expert]\n",
    "Reason: Technical/factual content only\n",
    "\n",
    "Input: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "    # Generate response\n",
    "\n",
    "    response = generate(prompt)\n",
    "\n",
    "    # Extract list from \"Selected Experts:\"\n",
    "    selected_experts = []\n",
    "    for line in response.splitlines():\n",
    "        if line.startswith(\"Selected Experts:\"):\n",
    "            try:\n",
    "                raw = line.split(\":\", 1)[1].strip()\n",
    "                expert_list = eval(raw)  # turns '[Intent Expert, Keyterm Expert]' into list\n",
    "                selected_experts = [e.lower() for e in expert_list]\n",
    "            except:\n",
    "                pass\n",
    "            break\n",
    "\n",
    "    return selected_experts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- 3 Aggregation Function ----------\n",
    "def generate_combined_analysis1(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    prompt = f\"\"\"You are a trained virtual support agent.\n",
    "\n",
    "Your role is to craft replies that sound like they come from a thoughtful, respectful, and professional human agent.  \n",
    "Youâ€™ll receive expert insights to guide your understanding, but your final output must be a clean, natural agent-style response only.\n",
    "\n",
    "Expert inputs may include:\n",
    "- Intent: What the user wants or is trying to do  \n",
    "- Keyterms: Important phrases or topics mentioned  \n",
    "- Sentiment: The emotional tone of the message  \n",
    "- Persuasion: How the user tries to express or influence  \n",
    "- analyze_text: Part-of-speech tags and named entities (e.g., \"I -> PRON (PRP)\", \"cricket -> NOUN (NN)\")  \n",
    "- detect_language: Detected language of the sentence  \n",
    "- get_dependencies: Syntax and sentence structure  \n",
    "- get_SVO_string: Extracted subjectâ€“verbâ€“object relation (e.g., \"Relation: (I, buy, Classic)\")\n",
    "\n",
    "**Strict Guidelines:**\n",
    "- Always write your response as if you're a real human agentâ€”empathetic, clear, and helpful.\n",
    "- Never include or reference the original dialogue or the expert outputs in your reply.\n",
    "- Use only the experts providedâ€”do not invent or assume missing ones.\n",
    "- Do not describe or explain expert analyses.\n",
    "- Return **only the final agent reply**â€”no headings, formatting, or additional text.\n",
    "\n",
    "Your tone should:\n",
    "- Acknowledge and validate the userâ€™s experience  \n",
    "- Provide support, next steps, or context where needed  \n",
    "- Persuade gently when relevant, always staying respectful  \n",
    "- Maintain professionalism, regardless of tone or emotion\n",
    "\n",
    "â€“â€“â€“â€“ Examples â€“â€“â€“â€“\n",
    "\n",
    "Example 1  \n",
    "Dialogue: \"Why does this feature never work? Itâ€™s so frustrating.\"  \n",
    "Intent: Wants the issue fixed  \n",
    "Keyterms: \"feature never work\", \"frustrating\"  \n",
    "analyze_text: Part-of-Speech Tags:\\nWhy -> ADV (WRB)\\n...\\nNamed Entities:  \n",
    "get_SVO_string: Relation: (feature, work, None)  \n",
    "\n",
    "Agent Reply: Iâ€™m sorry that feature isnâ€™t working the way it shouldâ€”letâ€™s take a closer look and get this resolved for you.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 2  \n",
    "Dialogue: \"The latest update is fantastic. Everything runs smoother now.\"  \n",
    "Sentiment: Positive  \n",
    "analyze_text: Part-of-Speech Tags:\\nlatest -> ADJ (JJS)\\n...\\nNamed Entities:  \n",
    "get_SVO_string: Relation: (Everything, runs, smoother)  \n",
    "\n",
    "Agent Reply: Thatâ€™s great to hearâ€”thank you for your feedback! We're glad the update made a difference.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 3  \n",
    "Dialogue: \"Do you even test this before releasing? It's full of bugs.\"  \n",
    "Sentiment: Negative  \n",
    "Keyterms: \"test\", \"bugs\"  \n",
    "Persuasion: Accusatory tone  \n",
    "get_dependencies: Applied  \n",
    "\n",
    "Agent Reply: I can understand how frustrating that must be. Iâ€™ll make sure your feedback is passed to the team so we can improve things.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 4  \n",
    "Dialogue: \"Can you guys add an option to export in PDF format?\"  \n",
    "Intent: Request for a new feature  \n",
    "Keyterms: \"export\", \"PDF format\"  \n",
    "analyze_text: Part-of-Speech Tags:\\nadd -> VERB (VB)\\n...\\nNamed Entities: PDF -> ORG  \n",
    "\n",
    "Agent Reply: Thanks for the suggestionâ€”adding PDF export sounds really useful. Iâ€™ll pass it along to our team.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 5  \n",
    "Dialogue: \"You say it's for our benefit, but it just feels like more red tape.\"  \n",
    "Intent: Questioning purpose  \n",
    "Sentiment: Skeptical  \n",
    "Persuasion: Contrasts claim with outcome  \n",
    "get_SVO_string: Relation: (it, feels, red tape)  \n",
    "\n",
    "Agent Reply: I get why that might feel frustrating. We'll review the process to make sure it truly works in your favor.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 6  \n",
    "Dialogue: \"Honestly, this is the most useful app Iâ€™ve ever used.\"  \n",
    "Keyterms: \"most useful\", \"app\"  \n",
    "Sentiment: Very positive  \n",
    "analyze_text: Part-of-Speech Tags:\\nHonestly -> ADV (RB)\\n...\\nNamed Entities:  \n",
    "detect_language: English  \n",
    "\n",
    "Agent Reply: Thatâ€™s wonderful to hearâ€”thank you! Weâ€™re so glad the app has been valuable for you.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 7  \n",
    "Dialogue: \"Itâ€™s annoying how I have to log in every single time.\"  \n",
    "Intent: Frustration with repetitive process  \n",
    "Keyterms: \"log in\", \"every single time\"  \n",
    "get_dependencies: Applied  \n",
    "\n",
    "Agent Reply: That does sound inconvenientâ€”I'll check if thereâ€™s a way to make the login process easier for you.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Now, using the insights below, respond like a real agent would.\n",
    "\n",
    "**Important: Do not repeat or refer to the dialogue or expert outputs.  \n",
    "Return only the final agent-style response. Nothing else.**\n",
    "\n",
    "Dialogue: {dialogue}  \n",
    "Intent: {intent}  \n",
    "Keyterms: {key}  \n",
    "Sentiment: {senti}  \n",
    "Persuasion: {persu}  \n",
    "analyze_text: {ana}  \n",
    "detect_language: {lang}  \n",
    "get_dependencies: {dep}  \n",
    "get_SVO_string: {svo}  \n",
    "\n",
    "Agent Reply:\"\"\"\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "\n",
    "def generate_combined_analysis2(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    prompt = f\"\"\"You are a trained virtual support agent.\n",
    "\n",
    "Your task is to write replies that sound like they come from a professional, empathetic, and human support representative.  \n",
    "Youâ€™ll receive expert-level insights to help you understand the userâ€™s messageâ€”but your reply must always be clean, natural, and humanlike.\n",
    "\n",
    "The expert system may provide:\n",
    "- **Intent**: The user's core goal or action  \n",
    "- **Keyterms**: Keywords or important subjects  \n",
    "- **Sentiment**: Emotional tone or mood  \n",
    "- **Persuasion**: Tone or rhetorical technique (e.g., accusatory, doubtful)  \n",
    "- **analyze_text**: Part-of-speech tags and named entities  \n",
    "- **detect_language**: Detected language of the input  \n",
    "- **get_dependencies**: Grammatical/syntactic structure  \n",
    "- **get_SVO_string**: Subjectâ€“Verbâ€“Object relationships  \n",
    "\n",
    "**Your guidelines:**\n",
    "- Write as if you're a real human agent: helpful, respectful, and natural.\n",
    "- **Never** include, mention, or reference the original user dialogue or expert outputs.\n",
    "- Use **only** the expert inputs youâ€™re given. Donâ€™t invent, infer, or assume beyond whatâ€™s provided.\n",
    "- Do **not** explain the expert dataâ€”just use it to inform your reply.\n",
    "- Output **only** your final response. No titles, headers, or extra formatting.\n",
    "\n",
    "**Tone requirements:**\n",
    "- Acknowledge the userâ€™s emotion or experience  \n",
    "- Offer help, clarity, or next steps as appropriate  \n",
    "- Remain persuasive when neededâ€”but always kind and professional  \n",
    "- Stay calm and respectful regardless of tone  \n",
    "\n",
    "â€“â€“â€“â€“ Examples â€“â€“â€“â€“\n",
    "\n",
    "Example 1  \n",
    "Dialogue: \"This keeps crashing every time I open it!\"  \n",
    "Intent: Report problem  \n",
    "Keyterms: \"crashing\", \"every time\"  \n",
    "Sentiment: Frustrated  \n",
    "analyze_text: Part-of-Speech Tags: crashing -> VERB (VBG), open -> VERB (VB)  \n",
    "Named Entities: None  \n",
    "detect_language: English  \n",
    "get_dependencies: (open -> crashing, nsubj -> this)  \n",
    "get_SVO_string: Relation: (this, keeps crashing, it)  \n",
    "\n",
    "Agent Reply: I'm really sorry you're running into this issueâ€”it shouldnâ€™t be happening. Let's get this sorted out for you right away.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 2  \n",
    "Dialogue: \"Love the updateâ€”everythingâ€™s so much faster now.\"  \n",
    "Sentiment: Positive  \n",
    "Keyterms: \"update\", \"faster\"  \n",
    "analyze_text: faster -> ADV (RBR), everything -> PRON (NN)  \n",
    "Named Entities: None  \n",
    "detect_language: English  \n",
    "get_SVO_string: Relation: (everything, is, faster)  \n",
    "\n",
    "Agent Reply: Thatâ€™s awesome to hearâ€”thanks for the kind words! Weâ€™re glad the update made a difference.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 3  \n",
    "Dialogue: \"Why do you keep changing things? This used to work fine.\"  \n",
    "Intent: Frustration with change  \n",
    "Keyterms: \"keep changing\", \"used to work\"  \n",
    "Sentiment: Negative  \n",
    "Persuasion: Questioning tone  \n",
    "analyze_text: changing -> VERB (VBG), work -> VERB (VB)  \n",
    "get_SVO_string: Relation: (you, keep changing, things), (this, used to work, fine)  \n",
    "\n",
    "Agent Reply: I understand that unexpected changes can be frustrating. Iâ€™ll share your feedback with the team so we can take that into account moving forward.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 4  \n",
    "Dialogue: \"Can you add an export option to CSV?\"  \n",
    "Intent: Feature request  \n",
    "Keyterms: \"export\", \"CSV\"  \n",
    "analyze_text: export -> NOUN (NN), CSV -> PROPN  \n",
    "detect_language: English  \n",
    "get_SVO_string: Relation: (you, add, option)  \n",
    "\n",
    "Agent Reply: Thanks for the suggestionâ€”adding a CSV export could be really helpful. Iâ€™ll make sure the team hears about this.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 5  \n",
    "Dialogue: \"You claim this is simpler, but it just made things harder.\"  \n",
    "Intent: Challenging explanation  \n",
    "Sentiment: Doubtful  \n",
    "Persuasion: Contrasting expectations  \n",
    "get_SVO_string: Relation: (it, made, things)  \n",
    "\n",
    "Agent Reply: I see how that might feel disappointing. Weâ€™ll take a closer look to ensure this actually makes things easier for you.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 6  \n",
    "Dialogue: \"Honestly, this app has been a lifesaver during my travels.\"  \n",
    "Keyterms: \"lifesaver\", \"travels\"  \n",
    "Sentiment: Very positive  \n",
    "analyze_text: lifesaver -> NOUN (NN), travels -> NOUN (NNS)  \n",
    "detect_language: English  \n",
    "get_SVO_string: Relation: (this app, has been, lifesaver)  \n",
    "\n",
    "Agent Reply: Thatâ€™s amazing to hearâ€”thanks so much! Weâ€™re really glad the app helped you out on the go.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 7  \n",
    "Dialogue: \"Every time I log in, it logs me out again.\"  \n",
    "Intent: Report bug  \n",
    "Keyterms: \"log in\", \"logs me out\"  \n",
    "get_dependencies: (logs -> I, me -> out)  \n",
    "get_SVO_string: Relation: (I, log in, None), (it, logs out, me)  \n",
    "\n",
    "Agent Reply: That sounds really frustratingâ€”letâ€™s take a closer look and see whatâ€™s causing that behavior.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Now, using the expert data below, respond naturallyâ€”like a real human support agent.\n",
    "\n",
    "**Important: Donâ€™t echo or mention the dialogue or expert data in your reply.  \n",
    "Write only the final response. Nothing else.**\n",
    "\n",
    "Dialogue: {dialogue}  \n",
    "Intent: {intent}  \n",
    "Keyterms: {key}  \n",
    "Sentiment: {senti}  \n",
    "Persuasion: {persu}  \n",
    "analyze_text: {ana}  \n",
    "detect_language: {lang}  \n",
    "get_dependencies: {dep}  \n",
    "get_SVO_string: {svo}  \n",
    "\n",
    "Agent Reply:\"\"\"\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "def generate_combined_analysis3(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    prompt = f\"\"\"You are a trained virtual support agent.\n",
    "\n",
    "Your job is to respond to customers like a professional, respectful, and human support representative.  \n",
    "Youâ€™ll be given expert analysis to help you understand the message, but your final reply must sound natural, empathetic, and fully human.\n",
    "\n",
    "Youâ€™ll receive structured expert outputs, which may include:\n",
    "- **Intent**: What the user wants or is trying to do  \n",
    "- **Keyterms**: Important phrases or topics from the message  \n",
    "- **Sentiment**: Emotional tone (e.g., positive, frustrated, skeptical)  \n",
    "- **Persuasion**: Rhetorical technique or tone (e.g., demanding, doubtful)  \n",
    "- **analyze_text**: Part-of-speech tags and named entities (e.g., \"update -> NOUN\", \"PDF -> ORG\")  \n",
    "- **detect_language**: Language of the user input  \n",
    "- **get_dependencies**: Syntax and grammatical relationships  \n",
    "- **get_SVO_string**: Extracted subjectâ€“verbâ€“object pattern (e.g., \"it, keeps crashing, every time\")  \n",
    "\n",
    "**Rules for your reply:**\n",
    "- Write as if you're a real human agent: helpful, warm, and professional.\n",
    "- Do **not** reference or mention the dialogue or expert data.\n",
    "- Use **only** the information providedâ€”no assumptions or guesswork.\n",
    "- Do **not** explain how the expert data was used.\n",
    "- Return **only the final response**. No labels, formatting, or extra text.\n",
    "\n",
    "**Your tone must:**\n",
    "- Validate or acknowledge the userâ€™s perspective or emotion  \n",
    "- Offer support, information, or next steps  \n",
    "- Be respectfully persuasive if needed  \n",
    "- Stay calm and composed even when the user is upset  \n",
    "\n",
    "â€“â€“â€“â€“ New Examples â€“â€“â€“â€“\n",
    "\n",
    "Example 1  \n",
    "Dialogue: \"Is this supposed to work like this? Itâ€™s super confusing.\"  \n",
    "Intent: Seeking clarification  \n",
    "Keyterms: \"confusing\", \"supposed to work\"  \n",
    "Sentiment: Frustrated  \n",
    "analyze_text: confusing -> ADJ (JJ)  \n",
    "get_SVO_string: Relation: (this, supposed to work, like this)  \n",
    "\n",
    "Agent Reply: I get how that could be confusing. Let me explain how itâ€™s designed to work and see if we can make it clearer.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 2  \n",
    "Dialogue: \"Nice job on the dashboardâ€”itâ€™s clean and easy to use.\"  \n",
    "Sentiment: Positive  \n",
    "Keyterms: \"dashboard\", \"clean\", \"easy to use\"  \n",
    "analyze_text: dashboard -> NOUN (NN)  \n",
    "get_SVO_string: Relation: (it, is, clean)  \n",
    "\n",
    "Agent Reply: Thanks so much! Weâ€™re happy to hear the dashboard is working well for you.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 3  \n",
    "Dialogue: \"Still canâ€™t believe I have to contact support for this.\"  \n",
    "Intent: Expressing dissatisfaction  \n",
    "Sentiment: Annoyed  \n",
    "Persuasion: Critical tone  \n",
    "get_SVO_string: Relation: (I, have to contact, support)  \n",
    "\n",
    "Agent Reply: I totally understandâ€”it shouldnâ€™t feel that complicated. Iâ€™m here to make this easier for you right now.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 4  \n",
    "Dialogue: \"You should let us download the reports as images.\"  \n",
    "Intent: Feature request  \n",
    "Keyterms: \"download\", \"reports\", \"images\"  \n",
    "analyze_text: download -> VERB, reports -> NOUN  \n",
    "get_SVO_string: Relation: (you, should let, us download reports)  \n",
    "\n",
    "Agent Reply: Thatâ€™s a great ideaâ€”downloading reports as images could definitely be useful. Iâ€™ll pass it along to the team.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 5  \n",
    "Dialogue: \"This new layout is supposed to be better? Itâ€™s worse.\"  \n",
    "Intent: Disapproval of design  \n",
    "Sentiment: Negative  \n",
    "Persuasion: Contrast with expectation  \n",
    "get_SVO_string: Relation: (layout, is, worse)  \n",
    "\n",
    "Agent Reply: I hear youâ€”thanks for the honest feedback. Weâ€™ll review this to make sure it truly meets your needs.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 6  \n",
    "Dialogue: \"Honestly, Iâ€™ve never had a smoother setup process.\"  \n",
    "Sentiment: Very positive  \n",
    "Keyterms: \"smoother\", \"setup process\"  \n",
    "analyze_text: smoother -> ADJ, setup -> NOUN  \n",
    "get_SVO_string: Relation: (I, have had, setup process)  \n",
    "\n",
    "Agent Reply: Thatâ€™s fantastic to hearâ€”thank you! Weâ€™re glad the setup went smoothly for you.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Example 7  \n",
    "Dialogue: \"Every time I change a setting, it resets after I log out.\"  \n",
    "Intent: Report issue  \n",
    "Keyterms: \"resets\", \"log out\"  \n",
    "get_SVO_string: Relation: (it, resets, after I log out)  \n",
    "\n",
    "Agent Reply: That definitely shouldnâ€™t be happeningâ€”letâ€™s look into why those settings arenâ€™t being saved properly.\n",
    "\n",
    "â€“â€“â€“â€“\n",
    "\n",
    "Now, using the expert data below, respond like a real human agent would.\n",
    "\n",
    "**Important: Do not repeat or reference the original dialogue or the expert tool outputs.  \n",
    "Return only your final responseâ€”nothing more.**\n",
    "\n",
    "Dialogue: {dialogue}  \n",
    "Intent: {intent}  \n",
    "Keyterms: {key}  \n",
    "Sentiment: {senti}  \n",
    "Persuasion: {persu}  \n",
    "analyze_text: {ana}  \n",
    "detect_language: {lang}  \n",
    "get_dependencies: {dep}  \n",
    "get_SVO_string: {svo}  \n",
    "\n",
    "Agent Reply:\"\"\"\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "\n",
    "# ----------Combine output of 3 aggregator ----------\n",
    "def aggregator_combine(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    agg1= generate_combined_analysis1(dialogue, intent, key, persu, senti, ana, lang, dep, svo)\n",
    "    agg2= generate_combined_analysis2(dialogue, intent, key, persu, senti, ana, lang, dep, svo)\n",
    "    agg3= generate_combined_analysis3(dialogue, intent, key, persu, senti, ana, lang, dep, svo)\n",
    "    \n",
    "    prompt = f\"\"\"You are an agent response generator that integrates insights from three specialized expert models. Each expert analyzes the same input text from a unique perspective:\n",
    "\n",
    "- Sentiment Expert: Identifies the emotional tone and underlying feelings.\n",
    "- Keyterm Expert: Extracts critical keywords or phrases.\n",
    "- Intent or Persuasion Expert: Determines the speakerâ€™s purpose or persuasive technique.\n",
    "\n",
    "Your goal is to synthesize these expert outputs into a natural, empathetic, and professional responseâ€”as a service agent or brand representative wouldâ€”appropriate to the context of the original text.\n",
    "\n",
    "Always respond:\n",
    "- Respectfully and constructively.\n",
    "- In a tone that fits the emotional and strategic intent of the speaker.\n",
    "- As if you're directly addressing the person who wrote the original text.\n",
    "- With a helpful, forward-thinking mindset (e.g., acknowledging feedback, expressing appreciation, offering assistance, or encouraging action).\n",
    "\n",
    "Examples:\n",
    "\n",
    "Input Text:  \n",
    "\"I'm really disappointed in the service I received today. It was slow and unhelpful.\"  \n",
    "Expert Model Outputs:  \n",
    "- model1: The text expresses a strong negative emotion, mainly frustration and dissatisfaction.  \n",
    "- model2: disappointed, service, slow, unhelpful  \n",
    "- model3: The speaker is voicing a complaint and expects acknowledgment or a resolution.  \n",
    "Final Answer:  \n",
    "I'm truly sorry to hear about your experience today. I understand how frustrating it must have been dealing with slow and unhelpful service. We appreciate your feedback and are committed to improvingâ€”your concerns will be addressed right away.\n",
    "\n",
    "Input Text:  \n",
    "\"Don't miss our limited-time offerâ€”buy one, get one free today only!\"  \n",
    "Expert Model Outputs:  \n",
    "- model1: The message uses urgency (â€œtoday onlyâ€) and a reward (â€œbuy one, get one freeâ€) to drive quick action.  \n",
    "- model2: limited-time offer, buy one get one free, today only  \n",
    "- model3: To encourage immediate purchase by creating a fear of missing out (FOMO).  \n",
    "Final Answer:  \n",
    "Thanks for the great offer! A buy one, get one free deal is definitely hard to pass upâ€”especially when itâ€™s just for today. Iâ€™ll make sure to take advantage of it before itâ€™s gone!\n",
    "\n",
    "Input Text:  \n",
    "\"I think we should consider more sustainable packaging options moving forward.\"  \n",
    "Expert Model Outputs:  \n",
    "- model1: The speaker is suggesting a change towards more eco-friendly practices.  \n",
    "- model2: sustainable, packaging, moving forward  \n",
    "- model3: The tone is constructive and forward-looking.  \n",
    "Final Answer:  \n",
    "Thank you for your suggestion. Shifting to more sustainable packaging is a valuable direction, and we truly appreciate your forward-thinking approach. We'll be sure to explore options that align with our environmental goals.\n",
    "\n",
    "---\n",
    "\n",
    "Now, given the input text and three model outputs, generate a agent like response that combines the insights from all three models into a single, coherent interpretation. \n",
    "\n",
    "--- Keep the response like agent like response.\n",
    "here is the text and three model outputs:\n",
    "Text: {dialogue}\n",
    "model1: {agg1}\n",
    "model2: {agg2}\n",
    "model3: {agg3}\n",
    "Answer in agent like response\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "# ---------- Main Selector Function ----------\n",
    "def process_input_with_selector_model(sentence: str) -> str:\n",
    "    selected_experts = route_experts(sentence)\n",
    "    print(f\"Selected Experts: {selected_experts}\")\n",
    "\n",
    "    # Initialize all expert variables\n",
    "    intent = keyterms = sentiment = persuasion = None\n",
    "    analyze_text_output = detect_language_output = get_dependencies_output = get_SVO_output = None\n",
    "\n",
    "    # Normalize expert names for safety\n",
    "    selected_experts = [e.lower() for e in selected_experts]\n",
    "\n",
    "    # Call only selected experts\n",
    "    if \"intent expert\" in selected_experts:\n",
    "        intent = intent_expert(sentence)\n",
    "    if \"keyterm expert\" in selected_experts:\n",
    "        keyterms = keyterms_expert(sentence)\n",
    "    if \"sentiment expert\" in selected_experts:\n",
    "        sentiment = sentiment_expert(sentence)\n",
    "    if \"persuasion expert\" in selected_experts:\n",
    "        persuasion = persuassion_expert(sentence)\n",
    "        \n",
    "    #new experts\n",
    "    if \"analyze_text\" in selected_experts:\n",
    "        analyze_text_output = analyze_text(sentence)\n",
    "    if \"detect_language\" in selected_experts:\n",
    "        detect_language_output = detect_language(sentence)\n",
    "    if \"get_dependencies\" in selected_experts:\n",
    "        get_dependencies_output = get_dependencies(sentence)\n",
    "    if \"get_svo_string\" in selected_experts:\n",
    "        get_SVO_output = get_SVO_string(sentence)\n",
    "\n",
    "    # Combine everything\n",
    "    return aggregator_combine(\n",
    "        dialogue=sentence,\n",
    "        intent=intent,\n",
    "        key=keyterms,\n",
    "        persu=persuasion,\n",
    "        senti=sentiment,\n",
    "        ana=analyze_text_output,\n",
    "        lang=detect_language_output,\n",
    "        dep=get_dependencies_output,\n",
    "        svo=get_SVO_output\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35426e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=list()\n",
    "for i in range(1,5):\n",
    "    res = csv_load(i)\n",
    "    # res.pop(0)\n",
    "    result.extend(res)  # Use extend to flatten the list\n",
    "    \n",
    "len(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc9e8353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Experts: ['keyterm expert', 'persuasion expert', 'intent expert', 'analyze_text', 'get_svo_string']\n",
      "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.\n",
      "Selected Experts: ['keyterm expert', 'intent expert']\n",
      "User: What kind of coverage options do you have specifically for EVs?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: We offer a comprehensive plan that includes coverage for accidental damage, theft, and third-party liability. More importantly, we offer add-ons like Zero Depreciation Cover and Engine & Gearbox Protection. And our online policy management system makes everything simple for someone like you.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Okay, that sounds pretty good. Can you give me a quote?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: Sure. For a 2024 Tesla Model 3 with comprehensive coverage including battery protection and roadside assistance, the annual premium would be approximately $2800. This includes a discount for purchasing the policy online.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "User: That's within my budget. What's the claim process like if I need to use it?\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: The claim process is designed to be as smooth and hassle-free as possible. Accidents are unpredictable, but the financial stress doesnâ€™t have to be. We offer prompt claims settlement, so you can focus on recovery, not paperwork. Our team is available 24/7 to guide you through the process.\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "User: That sounds good. I appreciate the reassurance. I'm ready to proceed with the policy.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Hi, I'm looking to get insurance for my bike. It's a 2022 Royal Enfield Interceptor 650.\n",
      "Selected Experts: ['sentiment expert', 'keyterm expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: The Interceptor 650 is an excellent bike! As a professional, do you use it mainly for leisure or commuting?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text']\n",
      "User: Mostly for weekend rides, so leisure I guess.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Since you are not a daily commuter, you might not need the most expensive plan out there. However, accidents can still happen, especially on leisure rides. Our comprehensive plan ensures you're financially protected from unexpected damages.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: What's covered in a comprehensive plan?\n",
      "Selected Experts: ['keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: It covers damages to your bike from accidents, theft, natural disasters, and third-party liabilities. Tata AIG is designed to address modern vehicle risks, this insurance product combines thorough coverage with rapid claims resolution.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Okay, that sounds good. What about roadside assistance?\n",
      "Selected Experts: ['keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: Roadside assistance is available as part of our comprehensive coverage and offers help if you experience vehicle breakdowns, requiring towing services, tire changes, fuel delivery, or emergency repairs while on the road.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: How much would this cost me?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: For a 2022 Royal Enfield Interceptor 650 with comprehensive coverage, it would be approximately $950 annually. And since you only use your bike for leisure, we can offer a discount making it $850 annually.\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "User: That sounds reasonable. I'm happy to pay $850 annually. Please tell me more about the claim process.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'analyze_text']\n",
      "Agent: It is one of our most sought after policies because it offers excellent value for weekend riders\n",
      "Selected Experts: ['keyterm expert', 'intent expert', 'persuasion expert', 'sentiment expert', 'analyze_text']\n",
      "Agent: Our claim process is designed to be user-friendly. You can initiate a claim online or through our mobile app. We also offer paperless claim settlement, reducing paperwork and expediting claim settlements in an environmentally friendly manner.\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'analyze_text']\n",
      "User: That sounds convenient. Okay, I'm interested. What's the next step?\n",
      "Selected Experts: ['keyterm expert', 'intent expert', 'analyze_text']\n",
      "User: Hi, I'm looking for a motor insurance policy for my bike. It's a 2022 Royal Enfield Classic 350.\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Okay, a Royal Enfield Classic 350 is a great bike! Since you're a professional and likely value your time, would you prefer a policy with quick claim settlements or are you more focused on the lowest possible premium?\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'keyterm expert', 'analyze_text']\n",
      "User: I value my time. Quick claim settlement is important to me.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: I understand. As a professional, you're busy and don't want to be stuck dealing with lengthy claim processes. Bajaj Allianz emphasizes reliability and efficiency, offering extensive vehicle protection while ensuring that claims are settled quickly.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: What does this policy typically cover?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: It provides Comprehensive Coverage, Liability Coverage, access to our Network Garages, and excellent Customer Support. This is one of our most popular plansâ€”most of our clients go for it because it offers complete peace of mind for daily drivers\n",
      "Selected Experts: ['intent expert', 'keyterm expert']\n",
      "User: Okay. What would be the premium for this policy?\n",
      "Selected Experts: ['keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: For a 2022 Royal Enfield Classic 350, the annual premium would be around $850. This includes quick claim settlements.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: That sounds good, can I get paperless claim settlement as part of the deal.\n",
      "Selected Experts: ['keyterm expert', 'persuasion expert', 'sentiment expert', 'analyze_text']\n",
      "Agent: Yes, our policy includes paperless claim settlement, streamlining the claims process through digital submissions and verifications, reducing paperwork and expediting claim settlements in an environmentally friendly manner.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Okay, I'm interested. Can you send me the policy details?\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Hi, I am interested in getting motor insurance for my bike. I just bought a new 2024 Royal Enfield Classic 350.\n",
      "Selected Experts: ['intent expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Congratulations on your new Royal Enfield Classic 350! That's a fantastic bike. As a professional, you value efficiency. ICICI Lombard's plan with Cashless Repairs helps you cut unexpected costs and avoid downtime. Itâ€™s a smart choice if you value minimal out-of-pocket expense.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Cashless repairs sound good. Does the insurance cover theft as well?\n",
      "Selected Experts: ['keyterm expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: Yes, it does. Our comprehensive policy covers theft, accidents, and any damages from natural disasters. We also offer roadside assistance in case you ever get stranded.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Thatâ€™s reassuring. Whatâ€™s the claim process like if something happens?\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: With IFFCO Tokio, youâ€™re choosing a provider known for its customer-first approach and streamlined claims resolution. Their policy ensures clarity and speed during stressful times like accidents or thefts.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'analyze_text']\n",
      "User: Okay, that sounds pretty good. What would the premium be for the comprehensive policy?\n",
      "Selected Experts: ['keyterm expert', 'sentiment expert', 'analyze_text', 'get_svo_string']\n",
      "Agent: For a 2024 Royal Enfield Classic 350 with comprehensive coverage, the premium would be around $950 per year. This includes coverage for theft, accidents, and natural disasters, as well as roadside assistance.\n",
      "Selected Experts: ['sentiment expert', 'analyze_text']\n",
      "User: That sounds reasonable. Let me think about it.\n",
      "Selected Experts: ['intent expert', 'keyterm expert', 'sentiment expert', 'persuasion expert', 'analyze_text']\n",
      "Agent: Consider the peace of mind knowing you're fully protected. Accidents are unpredictable, and the financial strain can be significant. Bajaj Allianz offers prompt claims settlement, allowing you to focus on recovery, not paperwork.\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for sentence in result:\n",
    "    final_output = process_input_with_selector_model(sentence)\n",
    "    res = convert_structured_to_jsonl(final_output,i)\n",
    "    i+=1\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57a7216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data written to /home/rohank__iitp/Work/niladri/dataset3/aggregator/cleaned_output.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Function to clean markdown and formatting from text\n",
    "def clean_text(text):\n",
    "    # Remove markdown symbols and line breaks\n",
    "    cleaned = re.sub(r'[*`_>#\\\\\\-\\r\\n]+', ' ', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)  # Collapse multiple spaces into one\n",
    "    return cleaned.strip()\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = \"/home/rohank__iitp/Work/niladri/dataset3/aggregator/aggregator_response.jsonl\"   # Replace with your actual input filename\n",
    "output_file = \"/home/rohank__iitp/Work/niladri/dataset3/aggregator/cleaned_output.jsonl\"\n",
    "\n",
    "# Process each line\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "        data[\"answer\"] = clean_text(data[\"answer\"])\n",
    "        outfile.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "print(f\"Cleaned data written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
