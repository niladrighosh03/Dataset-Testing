{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13e853-e99d-4079-be8f-5d81593bab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 19:39:26.509276: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baf9514a7ed4874b524a7728fb99241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "MODEL_NAME = \"/scratch/rohank__iitp/Phi-3-medium-128k-instruct\"\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "\n",
    "tok.padding_side = \"right\"\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = tok.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1933f379-4ad5-48da-90cd-151f19f05666",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTENTS = {\n",
    "    \"Request_Insurance_Quote\",\n",
    "    \"Ask_Coverage_Details\",\n",
    "    \"Express_Concern\",\n",
    "    \"Request_Additional_Info\",\n",
    "    \"Confirm_Interest\",\n",
    "    \"Ask_Price_or_Premium\",\n",
    "}\n",
    "\n",
    "PRICE   = [\"price\",\"cost\",\"how much\",\"premium\",\"monthly\",\"annual\",\"rate\",\"fees\",\"discount\",\"emi\"]\n",
    "REQUEST = [\"get insurance\",\"get a quote\",\"need insurance\",\"need a quote\",\"buy insurance\",\"looking to get\",\"want insurance\",\"start policy\",\"sign up\",\"apply\",\"new policy\",\"renew my policy\",\"purchase a policy\",\"enroll\",\"quote\"]\n",
    "COVERAGE= [\"coverage\",\"cover\",\"covered\",\"benefit\",\"protection\",\"exclusion\",\"deductible\",\"battery\",\"accident\",\"theft\",\"fire\",\"own damage\",\"third party\",\"comprehensive\",\"zero dep\",\"zero depreciation\",\"roadside\",\"idv\",\"engine\",\"flood\",\"natural calamity\",\"personal accident\"]\n",
    "CONCERN = [\"concern\",\"worried\",\"worry\",\"priority\",\"afraid\",\"risk\",\"must have\",\"need to make sure\",\"i want to ensure\",\"make certain\",\"ensure\",\"make sure\"]\n",
    "CONFIRM = [\"sounds good\",\"go ahead\",\"proceed\",\"let's do it\",\"i agree\",\"i’d like to proceed\",\"i would like to proceed\",\"i want to proceed\",\"i'm interested\",\"sign me up\",\"yes please\",\"continue\",\"confirm\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b0920d-2c5d-4d01-83f1-8c9a741de9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc(s): return re.sub(r\"\\s+\", \" \", (s or \"\")).strip().lower()\n",
    "def contains_any(s, kws): return any(k in lc(s) for k in kws)\n",
    "def first_snippet(s, kws):\n",
    "    t = s or \"\"; tl = t.lower()\n",
    "    for k in kws:\n",
    "        i = tl.find(k)\n",
    "        if i >= 0:\n",
    "            return t[max(0, i-12): min(len(t), i+len(k)+18)].strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1d776b7-98d5-4ba7-90c4-be483b7867cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOTS = \"\"\"\n",
    "User: Do you cover battery fires and thermal incidents for EVs?\n",
    "<intent>Ask_Coverage_Details</intent>\n",
    "<reason>From the phrasing, this is a targeted query about protections rather than process or price. It specifically names protection types (“battery fires”, “thermal incidents”), which are hallmarks of a coverage inquiry, as evidenced by “cover battery fires and thermal incidents”.</reason>\n",
    "\n",
    "User: I’d like a quote for motor insurance on my 2024 Honda Civic.\n",
    "<intent>Request_Insurance_Quote</intent>\n",
    "<reason>This message initiates the purchase flow by explicitly asking to obtain a policy quote. The intent is to start insurance for a specific vehicle and year, as evidenced by “quote for motor insurance on my 2024 Honda Civic”.</reason>\n",
    "\n",
    "User: How much would the monthly premium be for a standard plan?\n",
    "<intent>Ask_Price_or_Premium</intent>\n",
    "<reason>The focus is on cost rather than features or process. It requests a price figure at a monthly cadence, which clearly frames a premium inquiry, as evidenced by “How much would the monthly premium be”.</reason>\n",
    "\"\"\".strip()\n",
    "\n",
    "PROMPT_TMPL = f\"\"\"You are an intent classifier for motor-insurance conversations.\n",
    "\n",
    "Label exactly ONE of these intents:\n",
    "1) Request_Insurance_Quote — user initiates interest in getting a quote/policy.\n",
    "2) Ask_Coverage_Details — user asks what is covered (battery, accidents, theft, exclusions, deductibles).\n",
    "3) Express_Concern — user states a specific concern/priority.\n",
    "4) Request_Additional_Info — user asks for clarification/process/docs/eligibility/timelines.\n",
    "5) Confirm_Interest — user agrees/approves/wants to proceed.\n",
    "6) Ask_Price_or_Premium — user asks about cost/premium/discounts/price breakdown.\n",
    "\n",
    "Guidelines:\n",
    "- Use ONLY the user message (ignore any agent text).\n",
    "- Choose exactly ONE label from the list above.\n",
    "- Provide a high-quality explanation inside <reason>...</reason> (1–2 sentences). It should be specific, reference category-defining cues, and end with “as evidenced by …” + a short quote/snippet.\n",
    "- Vary openings; do not always begin with “The user…”.\n",
    "- If the message is empty/unclear, default to Request_Additional_Info and note the lack of content.\n",
    "\n",
    "Few-shot examples:\n",
    "{FEW_SHOTS}\n",
    "\n",
    "Now classify and output ONLY:\n",
    "<intent>OneOf: Request_Insurance_Quote | Ask_Coverage_Details | Express_Concern | Request_Additional_Info | Confirm_Interest | Ask_Price_or_Premium</intent>\n",
    "<reason>1–2 precise sentences ending with “as evidenced by …” + a short quote.</reason>\n",
    "\n",
    "User: {{user_utt}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895d234e-37d0-4c22-9f38-ffd8f919688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_intent_reason(user_utt: str, max_new_tokens=180):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a careful, concise intent classifier.\"},\n",
    "        {\"role\": \"user\", \"content\": PROMPT_TMPL.format(user_utt=user_utt or \"\")},\n",
    "    ]\n",
    "    chat_text = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tok(chat_text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.0,   # deterministic\n",
    "        do_sample=False,\n",
    "        pad_token_id=model.config.pad_token_id,\n",
    "    )\n",
    "    gen = tok.decode(out[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    im = re.search(r\"<intent>\\s*([^<]+?)\\s*</intent>\", gen, flags=re.I|re.S)\n",
    "    rm = re.search(r\"<reason>\\s*([^<]+?)\\s*</reason>\", gen, flags=re.I|re.S)\n",
    "    intent = (im.group(1).strip() if im else \"\")\n",
    "    reason = (rm.group(1).strip() if rm else \"\")\n",
    "\n",
    "    if intent not in INTENTS:\n",
    "        intent = \"Request_Additional_Info\"\n",
    "    if reason and not reason.endswith(\".\"):\n",
    "        reason += \".\"\n",
    "    return intent, reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786373fe-90a4-491f-a71a-4033d8f413f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_intent_and_reason(intent, reason, user_utt):\n",
    "    user = user_utt or \"\"\n",
    "\n",
    "    if intent not in INTENTS or not intent:\n",
    "        intent = \"Request_Additional_Info\"\n",
    "\n",
    "    if intent == \"Request_Additional_Info\":\n",
    "        if contains_any(user, COVERAGE):\n",
    "            intent = \"Ask_Coverage_Details\"\n",
    "            if not reason:\n",
    "                snip = first_snippet(user, COVERAGE) or \"coverage details\"\n",
    "                reason = f\"This reads as a request for specific protections rather than process or cost, as evidenced by “{snip}”.\"\n",
    "        elif contains_any(user, PRICE):\n",
    "            intent = \"Ask_Price_or_Premium\"\n",
    "            if not reason:\n",
    "                snip = first_snippet(user, PRICE) or \"pricing\"\n",
    "                reason = f\"The focus is on cost and premium amount instead of features, as evidenced by “{snip}”.\"\n",
    "        elif contains_any(user, REQUEST):\n",
    "            intent = \"Request_Insurance_Quote\"\n",
    "            if not reason:\n",
    "                snip = first_snippet(user, REQUEST) or \"get a quote\"\n",
    "                reason = f\"The message initiates obtaining a policy/quote for a vehicle, as evidenced by “{snip}”.\"\n",
    "        elif contains_any(user, CONFIRM):\n",
    "            intent = \"Confirm_Interest\"\n",
    "            if not reason:\n",
    "                snip = first_snippet(user, CONFIRM) or \"proceed\"\n",
    "                reason = f\"It expresses agreement to move ahead rather than ask questions, as evidenced by “{snip}”.\"\n",
    "        elif contains_any(user, CONCERN):\n",
    "            intent = \"Express_Concern\"\n",
    "            if not reason:\n",
    "                snip = first_snippet(user, CONCERN) or \"concern\"\n",
    "                reason = f\"It highlights a priority or worry about protection, as evidenced by “{snip}”.\"\n",
    "\n",
    "    if reason and \"as evidenced by\" not in reason.lower():\n",
    "        snip = first_snippet(user, COVERAGE+PRICE+REQUEST+CONCERN+CONFIRM)\n",
    "        reason = reason.rstrip(\".\") + f', as evidenced by “{snip}”.'\n",
    "    if reason and not reason.endswith(\".\"):\n",
    "        reason += \".\"\n",
    "    return intent, reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41facbed-db47-4c94-8ecd-fb49da7364b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "INPUT_CSV  = \"/home/rohank__iitp/Work/niladri/Expert Datatset/Original Dataset.csv\"  \n",
    "OUTPUT_CSV = \"/home/rohank__iitp/Work/niladri/Expert Datatset/Persuasion/Intent_results.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "if \"user_utterance\" not in df.columns:\n",
    "    df[\"user_utterance\"] = \"\"\n",
    "df[\"intent\"] = \"\"\n",
    "df[\"reason\"] = \"\"\n",
    "\n",
    "if os.path.exists(OUTPUT_CSV):\n",
    "    done_df = pd.read_csv(OUTPUT_CSV)\n",
    "    processed_ids = set(done_df.index.tolist())\n",
    "else:\n",
    "    processed_ids = set()\n",
    "    done_df = df.copy()\n",
    "\n",
    "##TIme Adding\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "print(\"Started at--->\", start_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx in processed_ids:\n",
    "        continue  \n",
    "\n",
    "    intent, reason = predict_intent_reason(row[\"user_utterance\"])\n",
    "    intent, reason = correct_intent_and_reason(intent, reason, row[\"user_utterance\"])\n",
    "\n",
    "    df.at[idx, \"intent\"] = intent\n",
    "    df.at[idx, \"reason\"] = reason\n",
    "    done_df.loc[idx] = df.loc[idx]\n",
    "    done_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "end_time = datetime.now()\n",
    "print(\"Finished time--->\", end_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print(f\" completed in {end_time - start_time} seconds\")\n",
    "print(\"Processing complete. Results saved incrementally to:\", OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef0302-9647-41a5-afac-ebf84d47c9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
