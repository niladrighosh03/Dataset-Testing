{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f41f829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8306d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import math\n",
    "\n",
    "print(\"Loading Gemma3 4B model...\")\n",
    "model_path = \"/scratch/rohank__iitp/gemma3_4b_it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493b29ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(text: str) -> float:\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "\n",
    "    return math.exp(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aafa5319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.889538775015744"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_perplexity(\"H. The weather is perfect for a walk in the park. I agree, it's a great day to be outside.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e63c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-2 Score: 0.4887\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def compute_bleu2(candidate_sentence: str, reference_sentence: str) -> float:\n",
    "    \"\"\"\n",
    "    Computes BLEU-2 score (unigram + bigram with equal weights) between a candidate and reference sentence.\n",
    "\n",
    "    Args:\n",
    "        candidate_sentence (str): The generated sentence.\n",
    "        reference_sentence (str): The reference (ground truth) sentence.\n",
    "\n",
    "    Returns:\n",
    "        float: BLEU-2 score (between 0 and 1)\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    candidate_tokens = candidate_sentence.strip().split()\n",
    "    reference_tokens = reference_sentence.strip().split()\n",
    "    \n",
    "    # BLEU-2 with weights (0.5, 0.5) â†’ unigram and bigram equally\n",
    "    weights = (0.5, 0.5)\n",
    "    \n",
    "    # Optional smoothing to avoid zero scores for short or imperfect matches\n",
    "    smoothing = SmoothingFunction().method1\n",
    "\n",
    "    # Compute score\n",
    "    bleu2_score = sentence_bleu([reference_tokens], candidate_tokens, weights=weights, smoothing_function=smoothing)\n",
    "    \n",
    "    return bleu2_score\n",
    "\n",
    "\n",
    "cand = \"the cat is on the mat\"\n",
    "ref = \"there is a cat on the mat\"\n",
    "\n",
    "score = compute_bleu2(cand, ref)\n",
    "print(f\"BLEU-2 Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d1c9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bert_score import score\n",
    "\n",
    "def compute_bert_score_f1(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\", verbose=False):\n",
    "\n",
    "    P, R, F1 = score(candidates, references, lang=lang, model_type=model_type, verbose=verbose)\n",
    "    x=F1.tolist()\n",
    "    return float(x[0])   # Convert torch.Tensor to list for usability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b7fbeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "candidates = [\"The cat is on the mat\"]\n",
    "references = [\"Therat\"]\n",
    "\n",
    "bs_f1_scores = compute_bert_score_f1(candidates, references)\n",
    "# print(f\"BERTScore-F1: {bs_f1_scores[0]:.4f}\")\n",
    "type(bs_f1_scores)\n",
    "round(bs_f1_scores,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52ea4cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct-2 score: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def distinct_2(text):\n",
    "\n",
    "    words = text.strip().split()\n",
    "    if len(words) < 2:\n",
    "        return 0.0  # No bigrams can be formed\n",
    "\n",
    "    bigrams = [(words[i], words[i+1]) for i in range(len(words) - 1)]\n",
    "    total_bigrams = len(bigrams)\n",
    "    unique_bigrams = len(set(bigrams))\n",
    "\n",
    "    return unique_bigrams / total_bigrams\n",
    "\n",
    "# Example usage\n",
    "example_text = \"I like cat like cat I like cat\"\n",
    "print(\"Distinct-2 score:\", distinct_2(example_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88785237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 ->: 0.7692307692307692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_rouge1(reference, candidate):\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, candidate)\n",
    "    return scores['rouge1'].fmeasure  # returns a namedtuple with precision, recall, fmeasure\n",
    "\n",
    "# Example usage:\n",
    "ref = \"The cat sat on the mat.\"\n",
    "cand = \"The cat is sitting on the mat.\"\n",
    "result = calculate_rouge1(ref, cand)\n",
    "print(f\"ROUGE-1 ->: {result}\")\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"your_csv_file.csv\")\n",
    "\n",
    "# Initialize empty columns\n",
    "df['PPL'] = 0.0\n",
    "df['BLEU-2'] = 0.0\n",
    "df['BERTScore-F1'] = 0.0\n",
    "df['Distinct-2'] = 0.0\n",
    "df['ROUGE-1'] = 0.0\n",
    "\n",
    "# Process each row and update CSV after each change\n",
    "for i in range(len(df)):\n",
    "    agent_reply = str(df.loc[i, 'new_agent_reply'])\n",
    "    model_reply = str(df.loc[i, 'Gemma Allexp Response'])\n",
    "\n",
    "    df.loc[i, 'PPL'] = calculate_perplexity(model_reply)\n",
    "    df.loc[i, 'BLEU-2'] = compute_bleu2(model_reply, agent_reply)\n",
    "    df.loc[i, 'BERTScore-F1'] = compute_bert_score_f1([model_reply], [agent_reply])\n",
    "    df.loc[i, 'Distinct-2'] = distinct_2(model_reply)\n",
    "    df.loc[i, 'ROUGE-1'] = calculate_rouge1(agent_reply, model_reply)\n",
    "\n",
    "    # Write to CSV after every row\n",
    "    df.to_csv(\"live_updated_file.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
