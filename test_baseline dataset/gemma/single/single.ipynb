{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a829913",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Gemma3 4B model...\")\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\", \n",
    "    model=\"/scratch/rohank__iitp/gemma3_4b_it\",\n",
    "    device=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt:str) ->str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Build prompt\n",
    "    formatted_input = \"\"\n",
    "    for message in messages:\n",
    "        if isinstance(message[\"content\"], list): \n",
    "            for item in message[\"content\"]:\n",
    "                if item[\"type\"] == \"text\":\n",
    "                    formatted_input += f\"{message['role']}: {item['text']}\\n\"\n",
    "        else:\n",
    "            formatted_input += f\"{message['role']}: {message['content']}\\n\"\n",
    "    formatted_input += \"assistant:\"\n",
    "\n",
    "    # Generate response\n",
    "    output = pipe(formatted_input, max_new_tokens=100)[0][\"generated_text\"]\n",
    "\n",
    "    # Extract only the assistant's response\n",
    "    assistant_response = output[len(formatted_input):].strip()\n",
    "\n",
    "    return assistant_response.strip()\n",
    "\n",
    "\n",
    "generate(\"Tell about finance\")  # Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_response(dialogue):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Instruction:\n",
    "Continue the conversation as the insurance agent. Respond appropriately to the latest user message. \n",
    "And please be brief.\n",
    "\n",
    "    Give the reply for this query: {dialogue}\n",
    "    \"\"\"\n",
    "    return generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e777449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataset():\n",
    "\n",
    "    # Make sure your CSV has the columns: 'conversation_id', 'turn_no', 'utterance', 'new_agent_reply'\n",
    "    df = pd.read_csv('/home/rohank__iitp/Work/niladri/test_baseline dataset/train_conversation.csv')\n",
    "    # --- Response Generation and Incremental Saving ---\n",
    "\n",
    "    if not df.empty:\n",
    "        output_filename = '/home/rohank__iitp/Work/niladri/test_baseline dataset/gemma/single/gemma_single_dataset.csv'\n",
    "        header_written = False\n",
    "        \n",
    "        # Group by conversation_id to process one conversation at a time\n",
    "        grouped = df.groupby('conversation_id')\n",
    "\n",
    "        for conversation_id, group in grouped:\n",
    "            print(f\"\\nProcessing Conversation ID: {conversation_id}\")\n",
    "            \n",
    "            # Ensure the conversation turns are in chronological order\n",
    "            group = group.sort_values('turn_no')\n",
    "            conversation_history = \"\"\n",
    "            processed_rows = []\n",
    "\n",
    "            for index, row in group.iterrows():\n",
    "                # Construct the prompt with the history plus the current user utterance\n",
    "                sentence = \"Conversation History:\\n\" + conversation_history + \"Current Utterance: \" + f\"User: {row['utterance']}\\nAgent:\"\n",
    "                # Your debugging print statements\n",
    "                print(\"========================================================================================================================================\")\n",
    "                print(f\"Generating for conv_id: {row['conversation_id']}, turn: {row['turn_no']}\\nPROMPT:\\n{sentence}\")\n",
    "                print(\"========================================================================================================================================\")\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Generate the response\n",
    "                '''Change HereðŸ˜†ðŸ˜†ðŸ˜†ðŸ˜†'''\n",
    "                qwen_response = model_response(sentence)\n",
    "                \n",
    "                \n",
    "                # Create a dictionary from the original row and add the new response\n",
    "                current_row_data = row.to_dict()\n",
    "                current_row_data['Gemma Allexp Response'] = qwen_response\n",
    "                processed_rows.append(current_row_data)\n",
    "\n",
    "                # Update the history for the next turn in this conversation\n",
    "                conversation_history += f\"User: {row['utterance']}\\nAgent: {row['new_agent_reply']}\\n\"\n",
    "            \n",
    "            # Create a DataFrame for the just-processed conversation\n",
    "            processed_group_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "            # Append the processed conversation to the output CSV file\n",
    "            if not header_written:\n",
    "                # For the first conversation, write with header and overwrite the file\n",
    "                processed_group_df.to_csv(output_filename, index=False, mode='w')\n",
    "                header_written = True\n",
    "            else:\n",
    "                # For subsequent conversations, append without the header\n",
    "                processed_group_df.to_csv(output_filename, index=False, mode='a', header=False)\n",
    "            \n",
    "            print(f\"Conversation ID {conversation_id} has been processed and saved.\")\n",
    "\n",
    "        print(f\"\\nProcessing complete. All conversations have been saved to '{output_filename}'\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nDataFrame is empty. No responses were generated or saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98105a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\"Starting dataset creation...\")\n",
    "start_time = datetime.now()\n",
    "print(\"Started at--->\", start_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "create_dataset()\n",
    "# End timer\n",
    "end_time = datetime.now()\n",
    "print(\"Finished time\", end_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Print elapsed time\n",
    "print(f\"hey() completed in {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
