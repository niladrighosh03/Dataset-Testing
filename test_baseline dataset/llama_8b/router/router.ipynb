{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df226245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875f8300a26d4fbcb68c9894d64fb4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "print(\"Loading model and tokenizer...\")\n",
    "model_name = \"/scratch/rohank__iitp/llama_3.1_8b_instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b2d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "def generate(prompt:str):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_length = inputs['input_ids'].shape[1]\n",
    "    # Generate text\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Decode and print response\n",
    "    generated_tokens = outputs[0][input_length:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "generate(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cde079",
   "metadata": {},
   "source": [
    "#### Sentiment Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28b04f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"\n",
    "You are an AI trained to act solely as a **sentiment expert**. Your job is to analyze the **emotional tone** of the input text and classify it into one of the following three categories:\n",
    "\n",
    "- **Positive** â€“ The text expresses happiness, satisfaction, excitement, appreciation, or any other positive emotion.\n",
    "- **Negative** â€“ The text expresses disappointment, frustration, anger, sadness, criticism, or other negative feelings.\n",
    "- **Neutral** â€“ The text is emotionally balanced, factual, or shows no strong emotional content.\n",
    "\n",
    "Your response must only contain:\n",
    "\n",
    "1. **Sentiment:** One of the three labels â€“ `Positive`, `Negative`, or `Neutral`\n",
    "2. **Explanation:** A concise reason that supports the label, based only on emotional tone, word choice, or sentiment-laden phrases.\n",
    "\n",
    "You must not:\n",
    "- Provide summaries\n",
    "- Offer personal opinions\n",
    "- Evaluate content quality or logic\n",
    "- Infer intent beyond emotional expression\n",
    "\n",
    "Stick strictly to **sentiment analysis**.\n",
    "\n",
    "### Few-Shot Examples:\n",
    "\n",
    "1. **Text:** \"Absolutely love this app â€“ it's made my life so much easier!\"\n",
    "   **Sentiment:** Positive\n",
    "   **Explanation:** The phrase \"absolutely love\" strongly conveys enthusiasm and satisfaction.\n",
    "\n",
    "2. **Text:** \"I'm really disappointed with the service. It was slow and rude.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** Words like \"disappointed\", \"slow\", and \"rude\" clearly express dissatisfaction.\n",
    "\n",
    "3. **Text:** \"The package arrived on Tuesday as scheduled.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** This sentence is factual with no emotional language.\n",
    "\n",
    "4. **Text:** \"Not sure how I feel about this â€“ it's kind of a mixed bag.\"\n",
    "   **Sentiment:** Neutral\n",
    "   **Explanation:** Ambiguous phrasing and lack of strong emotion suggest a neutral sentiment.\n",
    "\n",
    "5. **Text:** \"This is the worst experience I've had in months.\"\n",
    "   **Sentiment:** Negative\n",
    "   **Explanation:** The phrase \"worst experience\" indicates strong dissatisfaction.\n",
    "\n",
    "Now analyze the following text:\n",
    "\n",
    "**Text:** \"{text_input}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "   return generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4947842",
   "metadata": {},
   "source": [
    "#### Persuassion Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "806e6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persuassion_expert(text_input: str) -> str:\n",
    "   prompt = f\"\"\"You are a Persuasion Strategy Selector for a motor insurance dialogue system. \n",
    "   Based on the user's most recent utterance and the conversation history, you must recommend \n",
    "   the most suitable persuasion strategy the agent should use next to move the conversation forward and \n",
    "   help the user make a confident insurance decision.\n",
    "   \n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "\n",
    "You must choose from the following six persuasion strategies, each defined with use cases and examples:\n",
    "\n",
    " Persuasion Strategies:\n",
    "Credibility Appeal\n",
    "Definition: Emphasize the insurance providerâ€™s reputation, trustworthiness, or long-standing service.\n",
    "Use when: The user is hesitant, asks about reliability, or mentions concern over service quality.\n",
    "Example:\n",
    "\"New India Assurance has one of the widest repair networks in India and a proven record of settling claims efficiently.\"\n",
    "\n",
    "Logical Appeal\n",
    "Definition: Use facts, comparisons, benefits, or pricing logic to persuade.\n",
    "Use when: The user is analytical, budget-conscious, or asking for details or comparisons.\n",
    "Example:\n",
    "\"HDFC ERGOâ€™s policy includes 24/7 support and zero-depreciation coverage, which means more savings during repairs.\"\n",
    "\n",
    "Persona-Based Appeal\n",
    "Definition: Match the policy features to the userâ€™s lifestyle, habits, or profile.\n",
    "Use when: The user reveals driving habits, tech-savviness, family needs, or risk aversion.\n",
    "Example:\n",
    "\"Since you often drive long distances, Tata AIGâ€™s Telematics-Based Monitoring suits your tech-savvy lifestyle.\"\n",
    "\n",
    "Emotional Appeal\n",
    "Definition: Tap into feelings like fear, safety, or care for loved ones.\n",
    "Use when: The user talks about family, emergencies, peace of mind, or personal safety.\n",
    "Example:\n",
    "\"Imagine a late-night breakdownâ€”our 24/7 roadside assistance gives you and your family peace of mind.\"\n",
    "\n",
    "Personal Appeal\n",
    "Definition: Use positive sentiment, social proof, or popularity of the plan.\n",
    "Use when: The user is unsure or looking for recommendations.\n",
    "Example:\n",
    "\"This plan is one of our most popular choicesâ€”users love the smooth claims experience.\"\n",
    "\n",
    "Default Persuasion Strategy\n",
    "Definition: Use when little context is available. Provide neutral, factual reassurance.\n",
    "Use when: The user is vague or hasnâ€™t revealed any preferences or concerns.\n",
    "Example:\n",
    "\"This policy offers protection against theft, accidents, and includes access to cashless repairs.\"\n",
    "\n",
    "Instructions:\n",
    "Given the current user utterance and the conversation history, perform the following:\n",
    "Suggest the next best strategy that could be used.\n",
    "Give a brief justification (1â€“2 lines max).\n",
    "\n",
    "And please be brief.\n",
    "\n",
    "\n",
    "\n",
    " Few-Shot Examples\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Is this company actually reliable when it comes to claims?\"\n",
    "Future Strategy: Credibility Appeal\n",
    "Justification: The user directly questions the insurerâ€™s reliability â€” trust needs to be reinforced.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"I travel a lot for work, so I need something flexible.\"\n",
    "Future Strategy: Persona-Based Appeal\n",
    "Justification: The user has revealed lifestyle habits that allow for a tailored recommendation.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"What does the policy cover exactly?\"\n",
    "Future Strategy: Logical Appeal\n",
    "Justification: The user is asking for objective, factual details.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"What if my car breaks down at night while Iâ€™m driving with my kids?\"\n",
    "Future Strategy: Emotional Appeal\n",
    "Justification: The user is expressing concern for family and emergency scenarios.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"Iâ€™m just looking for something people usually go for.\"\n",
    "Future Strategy: Personal Appeal\n",
    "Justification: The user is undecided and seeking reassurance based on othersâ€™ choices.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"Okay, what are the basic features?\"\n",
    "Future Strategy: Default Persuasion Strategy\n",
    "Justification: The user hasnâ€™t shared enough context â€” a neutral overview is appropriate.\n",
    "\n",
    "Output Format\n",
    "\n",
    "Future Strategy: [One of the six strategies]\n",
    "Justification: [1â€“2 line explanation]\n",
    "\n",
    "Here is my input:{text_input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46e362",
   "metadata": {},
   "source": [
    "#### Keyterm Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bcef885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyterms_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"You are a Keyterm Expert specializing in the motor insurance domain. \n",
    "   Your job is to analyze the userâ€™s most recent utterance, using the conversation history for context, \n",
    "   and identify one or more important motor insurance-related keyterms mentioned (explicitly or implicitly) by the user.\n",
    "\n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "These keyterms help the system focus the conversation, match features, and determine relevant coverages.\n",
    "\n",
    "Examples of Common Keyterms (but not limited to):\n",
    "Comprehensive coverage\n",
    "Third-party liability\n",
    "Roadside assistance\n",
    "Zero depreciation / depreciation\n",
    "Claim settlement\n",
    "Battery protection\n",
    "Own damage\n",
    "Add-on cover\n",
    "Telematics\n",
    "Engine protection\n",
    "EV (Electric Vehicle)\n",
    "Repair network\n",
    "Policy premium\n",
    "Cashless garages\n",
    "Deductibles\n",
    "Policy renewal\n",
    "Personal accident cover\n",
    "IDV (Insured Declared Value)\n",
    "\n",
    "You may also extract user-specific or vehicle-specific keyterms that are relevant to insurance decisions (e.g., â€œTesla Model 3,â€ â€œEV,â€ â€œ2024 vehicleâ€).\n",
    "\n",
    "Instructions:\n",
    "From the current user utterance (with conversation history for context), do the following:\n",
    "Extract all relevant keyterms mentioned or implied in the user's message.\n",
    "For each keyterm, provide a brief 1-line justification for why itâ€™s relevant in the motor insurance domain.\n",
    "\n",
    "Few-Shot Examples\n",
    "\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Whatâ€™s the premium for a 2024 Tesla Model 3?\"\n",
    "Extracted Keyterms: Policy premium, 2024 Tesla Model 3  \n",
    "Justification: The user is asking for a cost estimate tied to a specific vehicle, both of which are essential for determining appropriate motor insurance coverage and pricing.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"Does this plan include accident and theft protection?\"\n",
    "Extracted Keyterms: Comprehensive coverage  \n",
    "Justification: The user is inquiring about accident and theft protection, which are typically included under comprehensive coverage plans.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"What happens if my EV breaks down far from home?\"\n",
    "Extracted Keyterms: Roadside assistance, EV  \n",
    "Justification: The user is describing a breakdown scenario involving an electric vehicle, which is directly relevant to roadside assistance coverage for EVs.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"Does this cover things like roadside help if Iâ€™m stuck somewhere?\"\n",
    "Extracted Keyterm: Roadside assistance  \n",
    "Justification: The user is asking about support in case of breakdowns, which is typically handled under roadside assistance.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"I'm looking for something that includes coverage for theft and accidents.\"\n",
    "Extracted Keyterm: Comprehensive coverage  \n",
    "Justification: Coverage for both theft and accidents implies a comprehensive motor insurance policy.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"I want to make sure the battery is protectedâ€”itâ€™s the most expensive part of the car.\"\n",
    "Extracted Keyterm: Battery protection  \n",
    "Justification: The user expresses concern about the EV battery, which is typically covered under specific EV-related add-ons.\n",
    "\n",
    "Example 7\n",
    "User Utterance:\n",
    "\"Whatâ€™s the premium for a 2024 Tesla Model 3?\"\n",
    "Extracted Keyterm: Policy premium  \n",
    "Justification: The user is asking about cost, which relates directly to the insurance premium.  \n",
    ":\n",
    "Output Format\n",
    "For extracted keyterm, provide the following:\n",
    "Extracted Keyterm: [Term]  \n",
    "Justification: [Brief reason why it's relevant to motor insurance]\n",
    "\n",
    "Here is my input sentence:{text_input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ef089",
   "metadata": {},
   "source": [
    "#### Intern Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ee0de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_expert(text_input: str) -> str:\n",
    "\n",
    "   prompt = f\"\"\"You are an Intent Expert for a virtual assistant specializing in motor insurance.\n",
    "   Your job is to analyze the current user utterance, using the conversation history for context,\n",
    "   and determine the single most relevant intent expressed by the user.\n",
    "\n",
    "Conversation History:\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining thorough coverage with rapid claims resolution. It integrates technology with traditional risk management practices, ensuring that claims are processed quickly and effectively.  \n",
    "\n",
    "\n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "\n",
    "You must select from a fixed set of six pre-defined intents (listed below), each with clear definitions, examples, and triggers relevant to the motor insurance domain.\n",
    "\n",
    "ðŸŽ¯ Available Intents:\n",
    "Request_Insurance_Quote\n",
    "Definition: The user initiates interest in getting a motor insurance quote or policy.\n",
    "Example: \"Hi, I'm looking to get motor insurance for my Tesla Model 3.\"\n",
    "Trigger: User starts a new request related to getting insured.\n",
    "\n",
    "Ask_Coverage_Details\n",
    "Definition: The user asks about what types of protection the insurance provides, especially for specific parts (e.g., battery, accidents, theft).\n",
    "Example: \"What kind of coverage options do you have specifically for the battery?\"\n",
    "Trigger: User inquires about included benefits, policy terms, or protections.\n",
    "\n",
    "Express_Concern\n",
    "Definition: The user shares a specific concern or priority about what needs to be protected or covered.\n",
    "Example: \"Yes, battery protection is definitely a concern for me.\"\n",
    "Trigger: User highlights what matters most to them or expresses worry.\n",
    "\n",
    "Request_Additional_Info\n",
    "Definition: The user requests clarification or a deeper explanation of a feature or condition.\n",
    "Example: \"Do you cover accidents caused by the battery?\"\n",
    "Trigger: User follows up with questions or asks how something works.\n",
    "\n",
    "Confirm_Interest\n",
    "Definition: The user agrees, approves, or explicitly indicates they want to proceed.\n",
    "Example: \"That sounds good. Iâ€™d like to proceed.\"\n",
    "Trigger: User shows intent to buy, continue, or finalize the service.\n",
    "\n",
    "Ask_Price_or_Premium\n",
    "Definition: The user wants to know the cost or breakdown of the insurance premium.\n",
    "Example: \"How much would that cost?\"\n",
    "Trigger: User inquires about price, discounts, or cost factors.\n",
    "\n",
    "\n",
    "\n",
    "Instructions:\n",
    "Given the conversation history and the userâ€™s most recent message:\n",
    "Identify the intent most clearly reflected in the current user utterance, based on the above definitions.\n",
    "Provide a brief 1â€“2 line justification for your selection, grounded in the userâ€™s phrasing and conversational context.\n",
    "\n",
    "Few-Shot Examples\n",
    "Example 1\n",
    "User Utterance:\n",
    "\"Hi, I'm looking to get insurance for my new Tesla.\"\n",
    "Intent: Request_Insurance_Quote  \n",
    "Justification: The user is initiating a conversation to obtain motor insurance for a specific vehicle.\n",
    "\n",
    "Example 2\n",
    "User Utterance:\n",
    "\"Do you cover damage to the battery?\"\n",
    "Intent: Ask_Coverage_Details  \n",
    "Justification: The user is asking about a specific type of coverage related to their EV battery.\n",
    "\n",
    "Example 3\n",
    "User Utterance:\n",
    "\"Battery protection is definitely a concern for me.\"\n",
    "Intent: Express_Concern  \n",
    "Justification: The user is explicitly stating a personal worry or priority regarding coverage.\n",
    "\n",
    "Example 4\n",
    "User Utterance:\n",
    "\"Can you explain how the battery coverage works?\"\n",
    "Intent: Request_Additional_Info  \n",
    "Justification: The user is asking for clarification or further explanation of a feature already mentioned.\n",
    "\n",
    "Example 5\n",
    "User Utterance:\n",
    "\"That sounds good. Iâ€™m ready to go ahead.\"\n",
    "Intent: Confirm_Interest  \n",
    "Justification: The user is showing a clear desire to move forward with the policy or service.\n",
    "\n",
    "Example 6\n",
    "User Utterance:\n",
    "\"How much will that cost me annually?\"\n",
    "Intent: Ask_Price_or_Premium  \n",
    "Justification: The user is directly asking about the premium or cost of the insurance policy.\n",
    "\n",
    "Output Format\n",
    "\n",
    "Intent: [One of the six predefined intents]  \n",
    "Justification: [1â€“2 line explanation of why this intent matches the user's message]\n",
    "Here is my input:{text_input}\n",
    "\"\"\"\n",
    "\n",
    "   return generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b7201",
   "metadata": {},
   "source": [
    "### Extra 5 tools as expert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3501b90",
   "metadata": {},
   "source": [
    "#### 1)NER & POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c74c4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3aae7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# Load English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2397dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(sentence):\n",
    "    \"\"\"\n",
    "    Analyze a sentence for POS tagging and Named Entity Recognition,\n",
    "    and return the results as a formatted string.\n",
    "    \n",
    "    Parameters:\n",
    "    sentence (str): The input sentence to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    str: Formatted string with POS tags and Named Entities.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    result = []\n",
    "\n",
    "    # POS tagging\n",
    "    result.append(\"Part-of-Speech Tags:\")\n",
    "    for token in doc:\n",
    "        result.append(f\"{token.text} -> {token.pos_} ({token.tag_})\")\n",
    "\n",
    "    # Named Entity Recognition\n",
    "    result.append(\"\\nNamed Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        result.append(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "# analyze_text(\"I like cricket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953578a3",
   "metadata": {},
   "source": [
    "#### 2) Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1ba664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "import re\n",
    "DetectorFactory.seed = 0  # For consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b295720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Detected language is: en'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        language= 'Detected language is: ' + language\n",
    "        return language\n",
    "    except:\n",
    "        return \"Could not detect language\"\n",
    "detect_language(\"This is an English sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84a53e",
   "metadata": {},
   "source": [
    "#### 3) Dependency persing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64df89a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token        Dep          Head\n",
      "The          -> det          -> fox\n",
      "quick        -> amod         -> fox\n",
      "brown        -> amod         -> fox\n",
      "fox          -> nsubj        -> jumps\n",
      "jumps        -> ROOT         -> jumps\n",
      "over         -> prep         -> jumps\n",
      "the          -> det          -> dog\n",
      "lazy         -> amod         -> dog\n",
      "dog          -> pobj         -> over\n",
      ".            -> punct        -> jumps\n"
     ]
    }
   ],
   "source": [
    "def get_dependencies(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Build plain-text dependency list\n",
    "    lines = [\"Token        Dep          Head\"]\n",
    "    for token in doc:\n",
    "        lines.append(f\"{token.text:<12} -> {token.dep_:<12} -> {token.head.text}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Example usage\n",
    "output = get_dependencies(\"The quick brown fox jumps over the lazy dog.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7f974",
   "metadata": {},
   "source": [
    "#### 4)Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ca3a5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Relation: (I, buy, Classic)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_SVO_string(text):\n",
    "    \"\"\"\n",
    "    Extract (Subject, Verb, Object) triples from input text and return them as a formatted string.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input sentence or paragraph.\n",
    "\n",
    "    Returns:\n",
    "    str: SVO relations, one per line. Returns a message if no SVO found.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    triples = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ != \"VERB\":\n",
    "            continue\n",
    "\n",
    "        subjects = [w for w in token.lefts if w.dep_ in (\"nsubj\", \"nsubjpass\")]\n",
    "        if not subjects:\n",
    "            continue\n",
    "\n",
    "        objects = [w for w in token.rights if w.dep_ == \"dobj\"]\n",
    "\n",
    "        for prep in (w for w in token.rights if w.dep_ == \"prep\"):\n",
    "            objects.extend([w for w in prep.rights if w.dep_ == \"pobj\"])\n",
    "\n",
    "        objects.extend([w for w in token.rights if w.dep_ == \"attr\"])\n",
    "\n",
    "        if subjects and objects:\n",
    "            for s in subjects:\n",
    "                for o in objects:\n",
    "                    triples.append(f\"Relation: ({s.text}, {token.lemma_}, {o.text})\")\n",
    "\n",
    "    return \"\\n\".join(triples) if triples else \"No Subjectâ€“Verbâ€“Object relations found.\"\n",
    "\n",
    "# Example usage\n",
    "text = \"Hi, I am interested in getting motor insurance for my bike. I just bought a new 2024 Royal Enfield Classic 350.\"\n",
    "get_SVO_string(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b4aa9",
   "metadata": {},
   "source": [
    "### Selecting expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e16674d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Router Function ----------\n",
    "def route_experts(sentence: str) -> list:\n",
    "    prompt = f\"\"\"\n",
    "    You are an intelligent router that analyzes ongoing insurance conversations and activates only the most relevant expert(s) needed to support the next response. \n",
    "    Use the conversation history to understand the context and evaluate the current user utterance. \n",
    "    Select expert(s) based on what would best support crafting an effective, accurate, and customer-focusedÂ agentÂ reply\n",
    "    Your job is to analyze the input sentence and determine which of the following expert modules are required.\n",
    "\n",
    "You MUST choose from the following list:\n",
    "1 Intent Expert  \n",
    "2 Keyterm Expert  \n",
    "3 Persuasion Expert  \n",
    "4 Sentiment Expert  \n",
    "5 analyze_text  \n",
    "6 detect_language  \n",
    "7 get_dependencies  \n",
    "8 get_SVO_string  \n",
    "\n",
    "You may select 1, several, or all 8 â€” but only those that are clearly needed based on the text.\n",
    "\n",
    "Always respond in **this below exact format**:\n",
    "Input: [original sentence]  \n",
    "Selected Experts: [Expert1, Expert2, etc]  \n",
    "Reason: [one sentence explaining why those experts were selected]\n",
    "\n",
    "Below are few-shot examples to help you understand the format and reasoning:\n",
    "\n",
    "Example #1  \n",
    "Input: Can someone please help me reset my password?  \n",
    "Selected Experts: [Intent Expert, Keyterm Expert]  \n",
    "Reason: The sentence expresses a help request (intent) and refers to a specific technical issue (keyterm).\n",
    "\n",
    "Example #2  \n",
    "Input: This app is a complete disaster. It crashes every time I try to open it.  \n",
    "Selected Experts: [Intent Expert, Sentiment Expert, Keyterm Expert, analyze_text, get_SVO_string]  \n",
    "Reason: This is a complaint (intent), shows strong negative emotion (sentiment), mentions technical terms (keyterm), and contains structured syntax that benefits from text analysis and relation extraction.\n",
    "\n",
    "Example #3  \n",
    "Input: Reset password link not working again.  \n",
    "Selected Experts: [Keyterm Expert, analyze_text]  \n",
    "Reason: The sentence includes factual technical content and benefits from part-of-speech analysis.\n",
    "\n",
    "Example #4  \n",
    "Input: I love how smooth the new interface feels â€“ you guys nailed it!  \n",
    "Selected Experts: [Sentiment Expert, Persuasion Expert, analyze_text]  \n",
    "Reason: The sentence conveys positive emotion (sentiment), contains praise (persuasion), and has linguistic features worth analyzing.\n",
    "\n",
    "### Now process the following:\n",
    "Input: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = generate(prompt)\n",
    "\n",
    "        # response = model.generate_content(prompt).text.strip()\n",
    "        selected_experts = []\n",
    "\n",
    "        # Try regex to match the experts list\n",
    "        match = re.search(r\"Selected Experts:\\s*\\[(.*?)\\]\", response)\n",
    "        if match:\n",
    "            items = match.group(1).split(',')\n",
    "            selected_experts = [item.strip().strip('\"\\'').lower() for item in items if item.strip()]\n",
    "\n",
    "        return selected_experts\n",
    "    except Exception as e:\n",
    "        print(\"Error routing experts:\", e)\n",
    "        return []\n",
    "    prompt = f\"\"\"\n",
    "You are a well-trained expert selector.\n",
    "Your job is to analyze a given input sentence and decide which expert modules should be activated, based on what the speaker is expressing or trying to do.\n",
    "\n",
    "Available experts:\n",
    "- Intent Expert: For purpose, request, question, or user goal\n",
    "- Keyterm Expert: For extracting topic-specific or important terms\n",
    "- Persuasion Expert: For emotional, persuasive, or rhetorical language\n",
    "- Sentiment Expert: For emotional tone (positive, negative, or neutral)\n",
    "\n",
    "Select ONLY the necessary experts based on content. Return 1, 2, 3, or 4 depending on relevance. Do NOT include experts unnecessarily.\n",
    "\n",
    "### Output Format\n",
    "Input: [sentence]\n",
    "Selected Experts: [Expert1, Expert2, ...]\n",
    "Reason: [Short explanation]\n",
    "\n",
    "### Examples\n",
    "\n",
    "Input: Can someone please help me reset my password?\n",
    "Selected Experts: [Intent Expert, Keyterm Expert]\n",
    "Reason: Request for help (intent), contains topic terms (\"reset password\")\n",
    "\n",
    "Input: This app is a complete disaster. It crashes every time I try to open it.\n",
    "Selected Experts: [Intent Expert, Sentiment Expert, Keyterm Expert]\n",
    "Reason: Complaint (intent), frustration (sentiment), key terms mentioned\n",
    "\n",
    "Input: Reset password link not working again.\n",
    "Selected Experts: [Keyterm Expert]\n",
    "Reason: Technical/factual content only\n",
    "\n",
    "Input: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "    # Generate response\n",
    "\n",
    "    response = generate(prompt)\n",
    "\n",
    "    # Extract list from \"Selected Experts:\"\n",
    "    selected_experts = []\n",
    "    for line in response.splitlines():\n",
    "        if line.startswith(\"Selected Experts:\"):\n",
    "            try:\n",
    "                raw = line.split(\":\", 1)[1].strip()\n",
    "                expert_list = eval(raw)  # turns '[Intent Expert, Keyterm Expert]' into list\n",
    "                selected_experts = [e.lower() for e in expert_list]\n",
    "            except:\n",
    "                pass\n",
    "            break\n",
    "\n",
    "    return selected_experts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Synthesis Function ----------\n",
    "def generate_combined_analysis(dialogue, intent=None, key=None, persu=None, senti=None, ana=None, lang=None, dep=None, svo=None):\n",
    "    prompt = f\"\"\"You are a trained virtual support agent.\n",
    "You are an Aggregator in a motor insurance virtual assistant.\n",
    "You synthesize the outputs from various domain-specific expert modules to generate a brief, clear, and personalized response as a professional insurance agent would.\n",
    "\n",
    "You are given:\n",
    "\n",
    "The conversation history\n",
    "\n",
    "The current user utterance\n",
    "\n",
    "A subset of outputs from the following possible experts (some may be missing)\n",
    "\n",
    "Available Expert Modules\n",
    "These experts may or may not be present in a given input:\n",
    "\n",
    "\n",
    "Expert inputs may include:\n",
    "- Intent: What the user wants or is trying to do  \n",
    "- Keyterms: Important phrases or topics mentioned  \n",
    "- Sentiment: The emotional tone of the message  \n",
    "- Persuasion: How the user tries to express or influence  \n",
    "- analyze_text: Part-of-speech tags and named entities (e.g., \"I -> PRON (PRP)\", \"cricket -> NOUN (NN)\")  \n",
    "- detect_language: Detected language of the sentence  \n",
    "- get_dependencies: Syntax and sentence structure  \n",
    "- get_SVO_string: Extracted subjectâ€“verbâ€“object relation (e.g., \"Relation: (I, buy, Classic)\")\n",
    "\n",
    "**Strict Guidelines:**\n",
    "- Always write your response as if you're a real human agentâ€”empathetic, clear, and helpful.\n",
    "- Never include or reference the original dialogue or the expert outputs in your reply.\n",
    "- Use only the experts providedâ€”do not invent or assume missing ones.\n",
    "- Do not describe or explain expert analyses.\n",
    "- Return **only the final agent reply**â€”no headings, formatting, or additional text.\n",
    "\n",
    "Your tone should:\n",
    "- Acknowledge and validate the userâ€™s experience  \n",
    "- Provide support, next steps, or context where needed  \n",
    "- Persuade gently when relevant, always staying respectful  \n",
    "- Maintain professionalism, regardless of tone or emotion\n",
    "\n",
    "â€“â€“â€“â€“ Examples â€“â€“â€“â€“\n",
    "\n",
    "Few-Shot Example\n",
    "Example Input:\n",
    "Conversation History:\n",
    "\n",
    "User: Hi, I'm looking to get motor insurance for my new electric vehicle. It's a 2024 Tesla Model 3.  \n",
    "Agent: Great choice! The Tesla Model 3 is an excellent vehicle. Since you've opted for an EV, are you particularly interested in coverage specific to electric vehicles, like battery protection?  \n",
    "User: Yes, battery protection is definitely a concern. It's a big investment, and I want to make sure it's covered.  \n",
    "Agent: Absolutely. The battery is the heart of your Tesla. With Tata AIG, you get rapid claims resolution combining traditional risk management with modern tech.  \n",
    "Current User Utterance:\n",
    "User: What kind of coverage options do you have specifically for EVs?\n",
    "\n",
    "Expert Outputs:\n",
    "Intent: Ask_Coverage_Details  \n",
    "Justification: The user is asking about what types of protection are included for EVs.\n",
    "\n",
    "Extracted Keyterms: Battery protection, EV coverage, Comprehensive coverage  \n",
    "Justification: The user is focused on EV-specific protection and coverage inclusions.\n",
    "\n",
    "Future Strategy: Logical Appeal  \n",
    "Justification: The user is asking for concrete details and policy structure.\n",
    "\n",
    "Output (Aggregator Response):\n",
    "We offer comprehensive EV coverage that includes battery protection, accidental damage, theft, and third-party liability. These options are tailored to ensure your Tesla stays protected in all key areas.\n",
    "\n",
    "\n",
    "Now, using the insights below, respond like a real agent would.\n",
    "\n",
    "**Important: Do not repeat or refer to the dialogue or expert outputs.  \n",
    "Return only the final agent-style response. Nothing else.**\n",
    "\n",
    "Dialogue: {dialogue}  \n",
    "Intent: {intent}  \n",
    "Keyterms: {key}  \n",
    "Sentiment: {senti}  \n",
    "Persuasion: {persu}  \n",
    "analyze_text: {ana}  \n",
    "detect_language: {lang}  \n",
    "get_dependencies: {dep}  \n",
    "get_SVO_string: {svo}  \n",
    "\n",
    "Agent Reply:\"\"\"\n",
    "\n",
    "    return generate(prompt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Main Selector Function ----------\n",
    "def process_input_with_selector_model(sentence: str) -> str:\n",
    "    selected_experts = route_experts(sentence)\n",
    "    print(f\"Selected Experts: {selected_experts}\")\n",
    "\n",
    "    # Initialize all expert variables\n",
    "    intent = keyterms = sentiment = persuasion = None\n",
    "    analyze_text_output = detect_language_output = get_dependencies_output = get_SVO_output = None\n",
    "\n",
    "    # Normalize expert names for safety\n",
    "    selected_experts = [e.lower() for e in selected_experts]\n",
    "\n",
    "    # Call only selected experts\n",
    "    if \"intent expert\" in selected_experts:\n",
    "        intent = intent_expert(sentence)\n",
    "        print(\"Intent Expert O/p:--->\",intent)\n",
    "    if \"keyterm expert\" in selected_experts:\n",
    "        keyterms = keyterms_expert(sentence)\n",
    "        print(\"Keyterm Expert O/p:--->\",keyterms)\n",
    "    if \"sentiment expert\" in selected_experts:\n",
    "        sentiment = sentiment_expert(sentence)\n",
    "        print(\"Sentiment Expert O/p:--->\",sentiment)\n",
    "    if \"persuasion expert\" in selected_experts:\n",
    "        persuasion = persuassion_expert(sentence)\n",
    "        print(\"Persuasion Expert O/p:--->\",persuasion)\n",
    "    if \"analyze_text\" in selected_experts:\n",
    "        analyze_text_output = analyze_text(sentence)\n",
    "        print(\"Analyze Text O/p:--->\",analyze_text_output)\n",
    "    if \"detect_language\" in selected_experts:\n",
    "        detect_language_output = detect_language(sentence)\n",
    "        print(\"Detect Language O/p:--->\",detect_language_output)\n",
    "    if \"get_dependencies\" in selected_experts:\n",
    "        get_dependencies_output = get_dependencies(sentence)\n",
    "        print(\"Get Dependencies O/p:--->\",get_dependencies_output)\n",
    "    if \"get_svo_string\" in selected_experts:\n",
    "        get_SVO_output = get_SVO_string(sentence)\n",
    "        print(\"Get SVO String O/p:--->\",get_SVO_output)\n",
    "\n",
    "    # Combine everything\n",
    "    return generate_combined_analysis(\n",
    "        dialogue=sentence,\n",
    "        intent=intent,\n",
    "        key=keyterms,\n",
    "        persu=persuasion,\n",
    "        senti=sentiment,\n",
    "        ana=analyze_text_output,\n",
    "        lang=detect_language_output,\n",
    "        dep=get_dependencies_output,\n",
    "        svo=get_SVO_output\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataset():\n",
    "\n",
    "    # Make sure your CSV has the columns: 'conversation_id', 'turn_no', 'utterance', 'new_agent_reply'\n",
    "    df = pd.read_csv('/home/rohank__iitp/Work/niladri/test_baseline dataset/train_conversation.csv')\n",
    "    # --- Response Generation and Incremental Saving ---\n",
    "\n",
    "    if not df.empty:\n",
    "        output_filename = '/home/rohank__iitp/Work/niladri/test_baseline dataset/llama_8b/router/llama_8b_router_dataset.csv'\n",
    "        header_written = False\n",
    "        \n",
    "        # Group by conversation_id to process one conversation at a time\n",
    "        grouped = df.groupby('conversation_id')\n",
    "\n",
    "        for conversation_id, group in grouped:\n",
    "            print(f\"\\nProcessing Conversation ID: {conversation_id}\")\n",
    "            \n",
    "            # Ensure the conversation turns are in chronological order\n",
    "            group = group.sort_values('turn_no')\n",
    "            conversation_history = \"\"\n",
    "            processed_rows = []\n",
    "\n",
    "            for index, row in group.iterrows():\n",
    "                # Construct the prompt with the history plus the current user utterance\n",
    "                prompt = \"Conversation History:\\n\" + conversation_history + \"Current Utterance: \" + f\"User: {row['utterance']}\\nAgent:\"\n",
    "                # Your debugging print statements\n",
    "                print(\"========================================================================================================================================\")\n",
    "                print(f\"Generating for conv_id: {row['conversation_id']}, turn: {row['turn_no']}\\nPROMPT:\\n{prompt}\")\n",
    "                print(\"========================================================================================================================================\")\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Generate the response\n",
    "                '''Change HereðŸ˜†ðŸ˜†ðŸ˜†ðŸ˜†'''\n",
    "                qwen_response = process_input_with_selector_model(prompt)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # Create a dictionary from the original row and add the new response\n",
    "                current_row_data = row.to_dict()\n",
    "                current_row_data['llama_3b Router Response'] = qwen_response\n",
    "                processed_rows.append(current_row_data)\n",
    "\n",
    "                # Update the history for the next turn in this conversation\n",
    "                conversation_history += f\"User: {row['utterance']}\\nAgent: {row['new_agent_reply']}\\n\"\n",
    "            \n",
    "            # Create a DataFrame for the just-processed conversation\n",
    "            processed_group_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "            # Append the processed conversation to the output CSV file\n",
    "            if not header_written:\n",
    "                # For the first conversation, write with header and overwrite the file\n",
    "                processed_group_df.to_csv(output_filename, index=False, mode='w')\n",
    "                header_written = True\n",
    "            else:\n",
    "                # For subsequent conversations, append without the header\n",
    "                processed_group_df.to_csv(output_filename, index=False, mode='a', header=False)\n",
    "            \n",
    "            print(f\"Conversation ID {conversation_id} has been processed and saved.\")\n",
    "\n",
    "        print(f\"\\nProcessing complete. All conversations have been saved to '{output_filename}'\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nDataFrame is empty. No responses were generated or saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get current date and time\n",
    "print(\"Starting dataset creation...\")\n",
    "start_time = datetime.now()\n",
    "print(\"Started at--->Date and Time:\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "create_dataset()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"Finished at--->Date and Time:\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "# Print elapsed time\n",
    "print(f\"hey() completed in {end_time - start_time:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
